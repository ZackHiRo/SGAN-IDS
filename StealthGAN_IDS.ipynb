{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StealthGAN-IDS Training on Google Colab\n",
    "\n",
    "This notebook provides a complete pipeline for training and evaluating StealthGAN-IDS on Google Colab.\n",
    "\n",
    "**Features:**\n",
    "- Automatic GPU detection and setup\n",
    "- Dataset download and preprocessing\n",
    "- Training with checkpointing\n",
    "- Evaluation and visualization\n",
    "- Easy result download\n",
    "\n",
    "**Supported Datasets:**\n",
    "- NSL-KDD (legacy)\n",
    "- CIC-IDS2017\n",
    "- CIC-IDS2018\n",
    "- UNSW-NB15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "CUDA version: 12.8\n",
      "GPU Memory: 33.66 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected! Training will be very slow on CPU.\")\n",
    "    print(\"Go to Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected environment: /workspace\n",
      "Repository directory: /workspace/SGAN-IDS\n",
      "‚úÖ Repository found at /workspace/SGAN-IDS\n",
      "Already up to date.\n",
      "Working directory: /workspace/SGAN-IDS\n",
      "Repository root: /workspace/SGAN-IDS\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "# Auto-detect environment (Colab vs QuickPod vs local)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect base directory\n",
    "if Path(\"/workspace\").exists():\n",
    "    # QuickPod environment\n",
    "    base_dir = Path(\"/workspace\")\n",
    "elif Path(\"/content\").exists():\n",
    "    # Google Colab environment\n",
    "    base_dir = Path(\"/content\")\n",
    "else:\n",
    "    # Local or other environment\n",
    "    base_dir = Path.cwd()\n",
    "\n",
    "repo_dir = base_dir / \"SGAN-IDS\"\n",
    "repo_url = \"https://github.com/yourusername/SGAN-IDS.git\"  # ‚ö†Ô∏è UPDATE THIS if cloning\n",
    "\n",
    "print(f\"Detected environment: {base_dir}\")\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "\n",
    "# Check if repo exists in current directory or base directory\n",
    "if repo_dir.exists():\n",
    "    print(f\"‚úÖ Repository found at {repo_dir}\")\n",
    "    os.chdir(repo_dir)\n",
    "    if (repo_dir / \".git\").exists():\n",
    "        !git pull\n",
    "elif Path(\"SGAN-IDS\").exists():\n",
    "    # Check if repo is in current working directory\n",
    "    repo_dir = Path(\"SGAN-IDS\").resolve()\n",
    "    print(f\"‚úÖ Repository found at {repo_dir}\")\n",
    "    os.chdir(repo_dir)\n",
    "elif Path.cwd().name == \"SGAN-IDS\":\n",
    "    # Already in the repo directory\n",
    "    repo_dir = Path.cwd()\n",
    "    print(f\"‚úÖ Already in repository directory: {repo_dir}\")\n",
    "else:\n",
    "    # Try to clone or use current directory\n",
    "    if repo_url != \"https://github.com/yourusername/SGAN-IDS.git\":\n",
    "        print(f\"Cloning repository to {repo_dir}...\")\n",
    "        !git clone {repo_url} {repo_dir}\n",
    "        os.chdir(repo_dir)\n",
    "    else:\n",
    "        # Use current directory as repo (for QuickPod where files are already there)\n",
    "        repo_dir = Path.cwd()\n",
    "        print(f\"‚ö†Ô∏è  Using current directory as repository: {repo_dir}\")\n",
    "        print(\"If this is wrong, update repo_url above or ensure SGAN-IDS folder exists\")\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Repository root: {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2.9.1+cu128 already installed with CUDA support ‚úì\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m‚úÖ Dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "# Check if torch is already installed with CUDA support (Colab has it pre-installed)\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Installing PyTorch with CUDA support...\")\n",
    "    !pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "else:\n",
    "    print(f\"PyTorch {torch.__version__} already installed with CUDA support ‚úì\")\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Optional: Install additional evaluation dependencies\n",
    "!pip install -q xgboost lightgbm pyyaml\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Setup\n",
    "\n",
    "Choose your dataset and download/prepare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataset: cic_ids2018\n",
      "Data root: /workspace/data\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect data root based on environment\n",
    "if Path(\"/workspace\").exists():\n",
    "    DATA_ROOT = Path(\"/workspace/data\")  # QuickPod\n",
    "elif Path(\"/content\").exists():\n",
    "    DATA_ROOT = Path(\"/content/data\")  # Colab\n",
    "else:\n",
    "    DATA_ROOT = Path(\"./data\")  # Local\n",
    "\n",
    "DATA_ROOT.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "DATASET = \"cic_ids2018\"  # Options: nsl_kdd, cic_ids2017, cic_ids2018, unsw_nb15, unified\n",
    "\n",
    "print(f\"Selected dataset: {DATASET}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIC-IDS2018 from Kaggle (requires Kaggle API)\n",
    "# Option 1: Using Kaggle API (recommended)\n",
    "if DATASET == \"cic_ids2018\":\n",
    "    print(\"To download CIC-IDS2018:\")\n",
    "    print(\"1. Install Kaggle: !pip install kaggle\")\n",
    "    print(\"2. Upload kaggle.json (from Kaggle account settings)\")\n",
    "    print(\"3. Run: !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\")\n",
    "    print(\"4. Then run:\")\n",
    "    print(f\"   !kaggle datasets download -d solarmainframe/ids-intrusion-csv -p {DATA_ROOT}\")\n",
    "    print(f\"   !unzip -q {DATA_ROOT}/ids-intrusion-csv.zip -d {DATA_ROOT}/CIC-IDS2018\")\n",
    "    print(\"\\n‚ö†Ô∏è  Or manually upload dataset files via Colab file browser\")\n",
    "\n",
    "# Option 2: Manual upload via Colab file browser\n",
    "# Files > Upload to session storage > Extract to DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /workspace/SGAN-IDS\n",
      "Repository: /workspace/SGAN-IDS\n"
     ]
    }
   ],
   "source": [
    "# Quick fix for QuickPod - set paths manually\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# QuickPod paths\n",
    "repo_dir = Path(\"/workspace/SGAN-IDS\")\n",
    "os.chdir(repo_dir)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Repository: {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Dataset cic_ids2018 will be preprocessed automatically during training\n",
      "Skipping standalone preprocessing step...\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset (optional - training will preprocess if needed)\n",
    "# Note: preprocess_data.py only supports: nsl_kdd, cic_ids2017, unified\n",
    "# For cic_ids2018 and unsw_nb15, preprocessing happens automatically during training\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Only preprocess if dataset is supported by preprocess script\n",
    "if DATASET in [\"nsl_kdd\", \"cic_ids2017\", \"unified\"]:\n",
    "    print(f\"Preprocessing {DATASET}...\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \"scripts/preprocess_data.py\",\n",
    "        \"--data-root\", str(DATA_ROOT),\n",
    "        \"--dataset\", DATASET\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, cwd=repo_dir)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Preprocessing complete!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Preprocessing failed with exit code {result.returncode}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Dataset {DATASET} will be preprocessed automatically during training\")\n",
    "    print(\"Skipping standalone preprocessing step...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning (Optional)\n",
    "\n",
    "Use Optuna to automatically find optimal hyperparameters before full training.\n",
    "This step is optional but recommended for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning Configuration:\n",
      "  Trials: 30\n",
      "  Epochs per trial: 15\n",
      "  Samples: 100000\n",
      "\n",
      "‚ö†Ô∏è  Tuning can take 1-3 hours depending on settings.\n"
     ]
    }
   ],
   "source": [
    "# Tuning configuration\n",
    "# Use fewer samples and epochs for faster tuning\n",
    "TUNE_TRIALS = 30  # Number of Optuna trials (more = better results, slower)\n",
    "TUNE_EPOCHS = 15  # Epochs per trial (fewer = faster, less accurate)\n",
    "TUNE_SAMPLES = 100000  # Samples for tuning (smaller = faster)\n",
    "SEED = 42\n",
    "\n",
    "print(\"Hyperparameter Tuning Configuration:\")\n",
    "print(f\"  Trials: {TUNE_TRIALS}\")\n",
    "print(f\"  Epochs per trial: {TUNE_EPOCHS}\")\n",
    "print(f\"  Samples: {TUNE_SAMPLES}\")\n",
    "print(\"\\n‚ö†Ô∏è  Tuning can take 1-3 hours depending on settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Command: python scripts/tune_optuna.py --data-root /workspace/data --dataset cic_ids2018 --n-trials 30 --tune-epochs 15 --max-samples 100000 --seed 42 --output best_hyperparams.json\n",
      "\n",
      "‚è≥ This will run multiple trials to find optimal hyperparameters.\n",
      "üí° Best parameters will be saved to best_hyperparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-19 07:18:30,671]\u001b[0m A new study created in memory with name: stealthgan_tuning\u001b[0m\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "StealthGAN-IDS Hyperparameter Tuning with Optuna\n",
      "============================================================\n",
      "[tune] Using device: cuda\n",
      "\n",
      "[1/3] Loading data...\n",
      "[tune] Limiting dataset to 100000 samples\n",
      "[CIC-IDS2018] Early stop after 1 files, ~150000 rows\n",
      "[CIC-IDS2018] Sampling 100000 from 150000 rows\n",
      "[CIC-IDS2018] Loaded shape: (100000, 80)\n",
      "[DataForge] Loaded datasets: ['cic_ids2018']\n",
      "[DataForge] Dropped 3 rows with NaN/inf values\n",
      "[DataForge] Data shape after cleaning: (24904, 80)\n",
      "[DataForge] Number of classes: 2\n",
      "[DataForge] Classes: ['Benign', 'FTP-BruteForce']\n",
      "[DataForge] Split sizes - Train: 17432, Val: 3736, Test: 3736\n",
      "[DataForge] Fitting transformers on training data...\n",
      "[DataForge] Transforming validation data...\n",
      "[DataForge] Transforming test data...\n",
      "[DataForge] Converting sparse to dense...\n",
      "[DataForge] Number of features after encoding: 4602\n",
      "[DataForge] Reducing dimensions from 4602 to 256 using TruncatedSVD...\n",
      "[DataForge] Explained variance: 98.59%\n",
      "[DataForge] Final number of features: 256\n",
      "[tune] Data: 256 features, 2 classes\n",
      "[tune] Train: 17432, Val: 3736\n",
      "\n",
      "[2/3] Creating Optuna study...\n",
      "\n",
      "[3/3] Running 30 trials (15 epochs each)...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:841: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Best trial: 0. Best value: 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [09:41<18:54, 56.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] lr_g=4.33e-05, lr_d=4.12e-04, critic=4, gp=12.4, fm=0.86, batch=256\n",
      "  Epoch 2: D=-730.42 G=1264.91 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.640\n",
      "  Epoch 5: D=-758.59 G=1257.36 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.619\n",
      "  Epoch 8: D=-756.62 G=1260.25 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.604\n",
      "  Epoch 11: D=-762.65 G=1252.38 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.601\n",
      "  Epoch 14: D=-771.99 G=1226.13 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.607\n",
      "\u001b[32m[I 2026-01-19 07:19:33,145]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'lr_g': 4.3284502212938785e-05, 'lr_d': 0.0004123206532618727, 'critic_updates': 4, 'gp_lambda': 12.374511199743695, 'feature_matching_weight': 0.864491338167939, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9996021075364038}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 1] lr_g=2.60e-04, lr_d=2.29e-05, critic=1, gp=4.5, fm=1.59, batch=64\n",
      "  Epoch 2: D=25.82 G=-5.39 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.237\n",
      "  Epoch 5: D=-7.07 G=2.77 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.233\n",
      "  Epoch 8: D=-27.81 G=17.31 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.890\n",
      "  Epoch 11: D=-67.86 G=71.50 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.285\n",
      "  Epoch 14: D=-110.09 G=157.10 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.829\n",
      "\u001b[32m[I 2026-01-19 07:20:27,421]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'lr_g': 0.00025959425503112657, 'lr_d': 2.2948683681130543e-05, 'critic_updates': 1, 'gp_lambda': 4.484685687215243, 'feature_matching_weight': 1.590786990501735, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9936269822486076}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 2] lr_g=5.95e-05, lr_d=2.16e-04, critic=1, gp=10.8, fm=3.00, batch=128\n",
      "  Epoch 2: D=-170.25 G=188.69 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.629\n",
      "  Epoch 5: D=-347.21 G=566.90 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.241\n",
      "  Epoch 8: D=-364.06 G=608.81 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.909\n",
      "  Epoch 11: D=-375.91 G=599.30 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.139\n",
      "  Epoch 14: D=-383.67 G=617.51 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.847\n",
      "\u001b[32m[I 2026-01-19 07:20:55,506]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'lr_g': 5.954553793888986e-05, 'lr_d': 0.0002157696745589684, 'critic_updates': 1, 'gp_lambda': 10.770454329858621, 'feature_matching_weight': 3.0028313874240085, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.998003133746353}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 3] lr_g=3.29e-05, lr_d=1.47e-05, critic=4, gp=9.4, fm=0.70, batch=256\n",
      "  Epoch 2: D=626.09 G=-38.42 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.650\n",
      "  Epoch 5: D=50.12 G=1.17 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.633\n",
      "  Epoch 8: D=2.40 G=4.63 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.609\n",
      "  Epoch 11: D=-15.09 G=8.35 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.599\n",
      "  Epoch 14: D=-40.67 G=23.14 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.719\n",
      "\u001b[32m[I 2026-01-19 07:21:58,290]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'lr_g': 3.292529363110524e-05, 'lr_d': 1.4653521030672129e-05, 'critic_updates': 4, 'gp_lambda': 9.362897381052425, 'feature_matching_weight': 0.6979873507394163, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9951486734096603}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 4] lr_g=8.49e-05, lr_d=2.06e-05, critic=5, gp=15.7, fm=4.70, batch=256\n",
      "  Epoch 2: D=256.41 G=-10.38 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.677\n",
      "  Epoch 5: D=18.93 G=0.10 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.667\n",
      "  Epoch 8: D=-49.56 G=22.41 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.808\n",
      "  Epoch 11: D=-201.28 G=157.97 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.085\n",
      "  Epoch 14: D=-383.93 G=531.54 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.811\n",
      "\u001b[32m[I 2026-01-19 07:23:05,851]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'lr_g': 8.488762161408708e-05, 'lr_d': 2.060924941320234e-05, 'critic_updates': 5, 'gp_lambda': 15.727523643861176, 'feature_matching_weight': 4.703544813664527, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9932207702745564}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 5] lr_g=4.57e-05, lr_d=2.89e-05, critic=5, gp=7.8, fm=1.48, batch=256\n",
      "  Epoch 2: D=9.94 G=7.28 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.540\n",
      "  Epoch 5: D=-160.60 G=183.22 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.658\n",
      "  Epoch 8: D=-482.55 G=810.85 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.288\n",
      "  Epoch 11: D=-677.84 G=1085.55 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.414\n",
      "  Epoch 14: D=-700.31 G=1237.87 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.706\n",
      "\u001b[32m[I 2026-01-19 07:24:12,890]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'lr_g': 4.574578205475403e-05, 'lr_d': 2.8907721743726727e-05, 'critic_updates': 5, 'gp_lambda': 7.778313207178196, 'feature_matching_weight': 1.4765790974681658, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9919672852471884}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 6] lr_g=1.02e-05, lr_d=2.43e-04, critic=4, gp=14.9, fm=3.88, batch=128\n",
      "  Epoch 2: D=-375.53 G=591.58 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.442\n",
      "  Epoch 5: D=-385.42 G=594.10 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.488\n",
      "  Epoch 8: D=-393.08 G=579.52 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.569\n",
      "  Epoch 11: D=-397.19 G=569.77 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.638\n",
      "  Epoch 14: D=-400.90 G=566.63 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.918\n",
      "\u001b[32m[I 2026-01-19 07:25:27,973]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'lr_g': 1.0218376758008082e-05, 'lr_d': 0.0002429095036825497, 'critic_updates': 4, 'gp_lambda': 14.851136192778759, 'feature_matching_weight': 3.8792246987611345, 'batch_size': 128, 'latent_dim': 64, 'ema_decay': 0.9906292276678317}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 7] lr_g=3.38e-05, lr_d=3.57e-05, critic=4, gp=13.1, fm=4.45, batch=256\n",
      "  Epoch 2: D=43.64 G=2.89 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.569\n",
      "  Epoch 5: D=-187.87 G=96.94 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.600\n",
      "  Epoch 8: D=-460.52 G=631.10 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.707\n",
      "  Epoch 11: D=-610.64 G=1053.71 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.833\n",
      "  Epoch 14: D=-670.86 G=1079.01 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.146\n",
      "\u001b[32m[I 2026-01-19 07:26:31,031]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'lr_g': 3.3755895712060835e-05, 'lr_d': 3.56842612325542e-05, 'critic_updates': 4, 'gp_lambda': 13.11359195574905, 'feature_matching_weight': 4.447342438624, 'batch_size': 256, 'latent_dim': 128, 'ema_decay': 0.9948885764040075}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 8] lr_g=7.73e-05, lr_d=5.33e-05, critic=1, gp=3.0, fm=0.25, batch=64\n",
      "  Epoch 2: D=-19.76 G=14.13 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.597\n",
      "  Epoch 5: D=-125.13 G=195.41 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.307\n",
      "  Epoch 8: D=-173.06 G=317.04 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.167\n",
      "  Epoch 11: D=-178.15 G=335.08 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.644\n",
      "  Epoch 14: D=-188.48 G=339.82 | F1 baseline=1.000 aug=1.000 (+0.0000) std=6.840\n",
      "\u001b[32m[I 2026-01-19 07:27:25,122]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'lr_g': 7.728716861851788e-05, 'lr_d': 5.3257327064372034e-05, 'critic_updates': 1, 'gp_lambda': 3.049937112872785, 'feature_matching_weight': 0.25400300986499785, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9974799562715762}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 9] lr_g=2.45e-05, lr_d=1.35e-05, critic=2, gp=4.1, fm=4.66, batch=256\n",
      "  Epoch 2: D=2822.45 G=-102.09 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.765\n",
      "  Epoch 5: D=307.36 G=-41.95 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.719\n",
      "  Epoch 8: D=143.54 G=-17.62 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.651\n",
      "  Epoch 11: D=46.80 G=0.62 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.642\n",
      "  Epoch 14: D=1.14 G=7.03 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [22:35<14:53, 81.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-19 07:28:11,615]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'lr_g': 2.4474916579073785e-05, 'lr_d': 1.3514082247401414e-05, 'critic_updates': 2, 'gp_lambda': 4.0632044578260835, 'feature_matching_weight': 4.655518496478608, 'batch_size': 256, 'latent_dim': 128, 'ema_decay': 0.995339488194965}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 10] lr_g=2.09e-04, lr_d=3.85e-04, critic=3, gp=18.7, fm=2.05, batch=128\n",
      "  Epoch 2: D=-357.78 G=634.41 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.631\n",
      "  Epoch 5: D=-451.85 G=879.55 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.711\n",
      "  Epoch 8: D=-450.21 G=887.17 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.119\n",
      "  Epoch 11: D=-444.22 G=887.39 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.705\n",
      "  Epoch 14: D=-444.44 G=887.72 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.628\n",
      "\u001b[32m[I 2026-01-19 07:29:10,895]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'lr_g': 0.00020917152515896608, 'lr_d': 0.0003845072704730259, 'critic_updates': 3, 'gp_lambda': 18.713516496323955, 'feature_matching_weight': 2.0491888857108758, 'batch_size': 128, 'latent_dim': 100, 'ema_decay': 0.999670793679352}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 11] lr_g=4.06e-04, lr_d=9.47e-05, critic=2, gp=5.5, fm=1.24, batch=64\n",
      "  Epoch 2: D=-177.71 G=320.74 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.796\n",
      "  Epoch 5: D=-194.57 G=355.18 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.123\n",
      "  Epoch 8: D=-195.52 G=349.77 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.191\n",
      "  Epoch 11: D=-198.30 G=360.90 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.551\n",
      "  Epoch 14: D=-197.64 G=343.87 | F1 baseline=1.000 aug=1.000 (+0.0000) std=8.030\n",
      "\u001b[32m[I 2026-01-19 07:30:36,274]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'lr_g': 0.0004063121630577901, 'lr_d': 9.474464387568003e-05, 'critic_updates': 2, 'gp_lambda': 5.457952379190472, 'feature_matching_weight': 1.243891003344493, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9933642513075156}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 12] lr_g=1.64e-04, lr_d=1.01e-04, critic=3, gp=1.1, fm=2.46, batch=64\n",
      "  Epoch 2: D=-199.02 G=330.67 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.523\n",
      "  Epoch 5: D=-206.50 G=338.43 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.550\n",
      "  Epoch 8: D=-202.72 G=343.72 | F1 baseline=1.000 aug=1.000 (+0.0000) std=6.358\n",
      "  Epoch 11: D=-198.74 G=353.53 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.937\n",
      "  Epoch 14: D=-198.95 G=349.54 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.571\n",
      "\u001b[32m[I 2026-01-19 07:32:32,555]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'lr_g': 0.00016425560326431137, 'lr_d': 0.00010121683418163727, 'critic_updates': 3, 'gp_lambda': 1.139055443205728, 'feature_matching_weight': 2.4567668961062554, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9972395387504799}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 13] lr_g=4.68e-04, lr_d=4.37e-04, critic=2, gp=7.5, fm=1.37, batch=64\n",
      "  Epoch 2: D=-203.38 G=316.66 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.909\n",
      "  Epoch 5: D=-208.98 G=319.98 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.534\n",
      "  Epoch 8: D=-205.02 G=314.99 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.140\n",
      "  Epoch 11: D=-207.92 G=294.05 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.983\n",
      "  Epoch 14: D=-207.84 G=307.06 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.984\n",
      "\u001b[32m[I 2026-01-19 07:33:57,752]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'lr_g': 0.00046780680673848344, 'lr_d': 0.0004372060036881607, 'critic_updates': 2, 'gp_lambda': 7.5131864770600085, 'feature_matching_weight': 1.3744445462831838, 'batch_size': 64, 'latent_dim': 100, 'ema_decay': 0.9992978820763153}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 14] lr_g=1.39e-04, lr_d=1.65e-04, critic=4, gp=12.2, fm=0.16, batch=64\n",
      "  Epoch 2: D=-187.93 G=293.78 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.790\n",
      "  Epoch 5: D=-193.14 G=270.91 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.294\n",
      "  Epoch 8: D=-198.46 G=265.76 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.934\n",
      "  Epoch 11: D=-196.60 G=273.35 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.787\n",
      "  Epoch 14: D=-198.95 G=263.68 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.198\n",
      "\u001b[32m[I 2026-01-19 07:36:26,145]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'lr_g': 0.00013944749260411379, 'lr_d': 0.00016484593138000155, 'critic_updates': 4, 'gp_lambda': 12.20646295097602, 'feature_matching_weight': 0.16438754701726088, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9964130800913097}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 15] lr_g=1.75e-05, lr_d=6.59e-05, critic=1, gp=18.8, fm=1.87, batch=256\n",
      "  Epoch 2: D=777.96 G=-26.16 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.637\n",
      "  Epoch 5: D=67.69 G=2.49 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.603\n",
      "  Epoch 8: D=-5.38 G=8.02 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.561\n",
      "  Epoch 11: D=-55.47 G=54.79 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.610\n",
      "  Epoch 14: D=-202.83 G=247.00 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.709\n",
      "\u001b[32m[I 2026-01-19 07:36:48,540]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'lr_g': 1.746598332001556e-05, 'lr_d': 6.589816029881827e-05, 'critic_updates': 1, 'gp_lambda': 18.816726782443986, 'feature_matching_weight': 1.8716743913963003, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9937281922141349}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 16] lr_g=2.41e-04, lr_d=1.07e-05, critic=3, gp=6.4, fm=3.09, batch=64\n",
      "  Epoch 2: D=9.39 G=-1.07 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.179\n",
      "  Epoch 5: D=-20.60 G=10.35 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.026\n",
      "  Epoch 8: D=-71.47 G=82.19 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.497\n",
      "  Epoch 11: D=-130.32 G=208.24 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.433\n",
      "  Epoch 14: D=-165.22 G=298.80 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.005\n",
      "\u001b[32m[I 2026-01-19 07:38:44,904]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'lr_g': 0.00024134047551034206, 'lr_d': 1.07321252145373e-05, 'critic_updates': 3, 'gp_lambda': 6.421663204595584, 'feature_matching_weight': 3.0853737854315115, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9902070443081857}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 17] lr_g=1.13e-04, lr_d=3.53e-05, critic=3, gp=9.5, fm=0.83, batch=256\n",
      "  Epoch 2: D=162.81 G=-14.00 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.734\n",
      "  Epoch 5: D=-8.76 G=0.66 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.701\n",
      "  Epoch 8: D=-109.75 G=69.31 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.339\n",
      "  Epoch 11: D=-320.36 G=383.22 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.002\n",
      "  Epoch 14: D=-480.37 G=783.95 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.786\n",
      "\u001b[32m[I 2026-01-19 07:39:40,328]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'lr_g': 0.00011308564631295108, 'lr_d': 3.53274750478157e-05, 'critic_updates': 3, 'gp_lambda': 9.508559732055215, 'feature_matching_weight': 0.8318506766926385, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9921115050227481}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 18] lr_g=3.01e-04, lr_d=1.33e-04, critic=2, gp=16.8, fm=0.94, batch=64\n",
      "  Epoch 2: D=-176.65 G=310.72 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.100\n",
      "  Epoch 5: D=-182.63 G=321.52 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.251\n",
      "  Epoch 8: D=-183.81 G=315.65 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.678\n",
      "  Epoch 11: D=-187.40 G=304.74 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.467\n",
      "  Epoch 14: D=-185.69 G=297.50 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.325\n",
      "\u001b[32m[I 2026-01-19 07:41:05,908]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'lr_g': 0.0003014191625595948, 'lr_d': 0.00013330838138162182, 'critic_updates': 2, 'gp_lambda': 16.803053928659196, 'feature_matching_weight': 0.9362037253240649, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9984527314497404}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 19] lr_g=5.30e-05, lr_d=5.57e-05, critic=5, gp=13.5, fm=1.94, batch=128\n",
      "  Epoch 2: D=-294.37 G=454.33 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.643\n",
      "  Epoch 5: D=-368.92 G=599.61 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [31:55<00:50, 50.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 8: D=-370.25 G=612.48 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.734\n",
      "  Epoch 11: D=-375.10 G=597.51 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.304\n",
      "  Epoch 14: D=-382.97 G=559.75 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.122\n",
      "\u001b[32m[I 2026-01-19 07:43:07,663]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'lr_g': 5.300907148719937e-05, 'lr_d': 5.5738676559539255e-05, 'critic_updates': 5, 'gp_lambda': 13.533989746918186, 'feature_matching_weight': 1.941924755842845, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9959168124080359}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 20] lr_g=1.12e-04, lr_d=2.26e-05, critic=4, gp=2.2, fm=2.58, batch=256\n",
      "  Epoch 2: D=118.73 G=-4.93 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.621\n",
      "  Epoch 5: D=-3.50 G=5.96 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.626\n",
      "  Epoch 8: D=-74.01 G=44.11 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.872\n",
      "  Epoch 11: D=-233.09 G=251.02 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.088\n",
      "  Epoch 14: D=-425.55 G=642.29 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.051\n",
      "\u001b[32m[I 2026-01-19 07:44:00,040]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'lr_g': 0.00011168136267625166, 'lr_d': 2.2648950518228282e-05, 'critic_updates': 4, 'gp_lambda': 2.154338597706424, 'feature_matching_weight': 2.5766943033111, 'batch_size': 256, 'latent_dim': 64, 'ema_decay': 0.9943304318815026}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 21] lr_g=5.90e-05, lr_d=2.64e-04, critic=1, gp=11.3, fm=3.77, batch=128\n",
      "  Epoch 2: D=-271.42 G=408.24 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.575\n",
      "  Epoch 5: D=-362.67 G=607.05 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.197\n",
      "  Epoch 8: D=-372.65 G=580.02 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.732\n",
      "  Epoch 11: D=-365.08 G=599.55 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.021\n",
      "  Epoch 14: D=-365.29 G=594.44 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.330\n",
      "\u001b[32m[I 2026-01-19 07:44:34,803]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'lr_g': 5.8986909446740275e-05, 'lr_d': 0.00026426679271043953, 'critic_updates': 1, 'gp_lambda': 11.274735167954246, 'feature_matching_weight': 3.7690804298943554, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9984621247770731}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 22] lr_g=3.60e-05, lr_d=2.76e-04, critic=1, gp=10.3, fm=2.99, batch=128\n",
      "  Epoch 2: D=-278.94 G=427.34 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.544\n",
      "  Epoch 5: D=-380.64 G=612.47 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.622\n",
      "  Epoch 8: D=-378.53 G=635.49 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.826\n",
      "  Epoch 11: D=-397.25 G=600.08 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.250\n",
      "  Epoch 14: D=-416.24 G=560.69 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.567\n",
      "\u001b[32m[I 2026-01-19 07:45:14,504]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'lr_g': 3.5989468151417884e-05, 'lr_d': 0.0002755883842399768, 'critic_updates': 1, 'gp_lambda': 10.297809553958587, 'feature_matching_weight': 2.98722005708893, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9982670901269358}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 23] lr_g=1.91e-05, lr_d=4.84e-04, critic=1, gp=9.1, fm=3.33, batch=128\n",
      "  Epoch 2: D=-353.02 G=612.35 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.668\n",
      "  Epoch 5: D=-383.73 G=617.12 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.646\n",
      "  Epoch 8: D=-395.45 G=597.09 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.628\n",
      "  Epoch 11: D=-399.51 G=583.80 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.620\n",
      "  Epoch 14: D=-395.34 G=578.78 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.623\n",
      "\u001b[32m[I 2026-01-19 07:45:54,195]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'lr_g': 1.911156245452031e-05, 'lr_d': 0.0004837247254176929, 'critic_updates': 1, 'gp_lambda': 9.068455382639925, 'feature_matching_weight': 3.3280698945686784, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9997956664297679}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 24] lr_g=9.45e-05, lr_d=1.79e-04, critic=2, gp=11.2, fm=2.38, batch=128\n",
      "  Epoch 2: D=-343.19 G=544.78 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.055\n",
      "  Epoch 5: D=-364.58 G=567.99 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.383\n",
      "  Epoch 8: D=-381.24 G=544.58 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.237\n",
      "  Epoch 11: D=-350.41 G=576.48 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.557\n",
      "  Epoch 14: D=-319.55 G=626.01 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.795\n",
      "\u001b[32m[I 2026-01-19 07:46:54,854]\u001b[0m Trial 24 finished with value: 0.0 and parameters: {'lr_g': 9.45363454914016e-05, 'lr_d': 0.0001786953739815619, 'critic_updates': 2, 'gp_lambda': 11.18655853826133, 'feature_matching_weight': 2.3834603943362187, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9969666989624716}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 25] lr_g=6.14e-05, lr_d=3.22e-04, critic=1, gp=5.4, fm=1.64, batch=128\n",
      "  Epoch 2: D=-336.57 G=497.86 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.588\n",
      "  Epoch 5: D=-402.19 G=540.46 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.951\n",
      "  Epoch 8: D=-344.90 G=630.58 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.982\n",
      "  Epoch 11: D=-375.91 G=617.52 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.769\n",
      "  Epoch 14: D=-364.82 G=634.53 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.663\n",
      "\u001b[32m[I 2026-01-19 07:47:31,684]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'lr_g': 6.140919633850076e-05, 'lr_d': 0.00032221888637698633, 'critic_updates': 1, 'gp_lambda': 5.380025075033217, 'feature_matching_weight': 1.6354198658460675, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9991173437174146}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 26] lr_g=2.38e-05, lr_d=2.25e-04, critic=2, gp=14.2, fm=0.57, batch=64\n",
      "  Epoch 2: D=-201.68 G=319.59 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.654\n",
      "  Epoch 5: D=-209.38 G=298.66 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.858\n",
      "  Epoch 8: D=-203.23 G=285.08 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.849\n",
      "  Epoch 11: D=-204.04 G=282.13 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.170\n",
      "  Epoch 14: D=-204.84 G=289.61 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.346\n",
      "\u001b[32m[I 2026-01-19 07:49:15,865]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'lr_g': 2.3783169482276286e-05, 'lr_d': 0.00022478120740468396, 'critic_updates': 2, 'gp_lambda': 14.236928701119698, 'feature_matching_weight': 0.5688382348338468, 'batch_size': 64, 'latent_dim': 100, 'ema_decay': 0.9923434572891496}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 27] lr_g=4.27e-05, lr_d=9.52e-05, critic=1, gp=12.3, fm=1.17, batch=128\n",
      "  Epoch 2: D=-13.27 G=8.08 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.546\n",
      "  Epoch 5: D=-199.90 G=246.39 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.682\n",
      "  Epoch 8: D=-328.50 G=546.98 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.704\n",
      "  Epoch 11: D=-335.50 G=584.17 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.447\n",
      "  Epoch 14: D=-354.92 G=602.29 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.192\n",
      "\u001b[32m[I 2026-01-19 07:49:50,998]\u001b[0m Trial 27 finished with value: 0.0 and parameters: {'lr_g': 4.273940303843007e-05, 'lr_d': 9.51736335477873e-05, 'critic_updates': 1, 'gp_lambda': 12.318875171691133, 'feature_matching_weight': 1.1678028390856015, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.9981581308426777}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "[Trial 28] lr_g=1.56e-04, lr_d=3.37e-04, critic=2, gp=8.0, fm=2.72, batch=256\n",
      "  Epoch 2: D=-558.89 G=893.12 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.678\n",
      "  Epoch 5: D=-732.40 G=1354.78 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.970\n",
      "  Epoch 8: D=-757.61 G=1328.61 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.870\n",
      "  Epoch 11: D=-759.91 G=1344.95 | F1 baseline=1.000 aug=1.000 (+0.0000) std=5.139\n",
      "  Epoch 14: D=-768.47 G=1317.68 | F1 baseline=1.000 aug=1.000 (+0.0000) std=4.268\n",
      "\u001b[32m[I 2026-01-19 07:50:26,027]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'lr_g': 0.00015622858693855712, 'lr_d': 0.00033711237429387013, 'critic_updates': 2, 'gp_lambda': 8.011687497852979, 'feature_matching_weight': 2.71894831728393, 'batch_size': 256, 'latent_dim': 64, 'ema_decay': 0.9958779179858631}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [34:48<00:00, 69.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 29] lr_g=2.68e-05, lr_d=1.26e-04, critic=4, gp=17.4, fm=0.55, batch=64\n",
      "  Epoch 2: D=-200.51 G=309.52 | F1 baseline=1.000 aug=1.000 (+0.0000) std=0.758\n",
      "  Epoch 5: D=-198.52 G=303.55 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.205\n",
      "  Epoch 8: D=-192.48 G=311.40 | F1 baseline=1.000 aug=1.000 (+0.0000) std=3.966\n",
      "  Epoch 11: D=-200.87 G=284.85 | F1 baseline=1.000 aug=1.000 (+0.0000) std=2.285\n",
      "  Epoch 14: D=-201.72 G=288.51 | F1 baseline=1.000 aug=1.000 (+0.0000) std=1.915\n",
      "\u001b[32m[I 2026-01-19 07:53:18,816]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'lr_g': 2.676822676846602e-05, 'lr_d': 0.00012553619932692753, 'critic_updates': 4, 'gp_lambda': 17.426457016105374, 'feature_matching_weight': 0.5465090978585505, 'batch_size': 64, 'latent_dim': 100, 'ema_decay': 0.997673899403075}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "============================================================\n",
      "TUNING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Study statistics:\n",
      "  Number of finished trials: 30\n",
      "  Number of pruned trials: 0\n",
      "  Number of complete trials: 30\n",
      "\n",
      "Best trial:\n",
      "  Value (F1 improvement): 0.0000\n",
      "  Params:\n",
      "    lr_g: 0.000043\n",
      "    lr_d: 0.000412\n",
      "    critic_updates: 4\n",
      "    gp_lambda: 12.374511\n",
      "    feature_matching_weight: 0.864491\n",
      "    batch_size: 256\n",
      "    latent_dim: 100\n",
      "    ema_decay: 0.999602\n",
      "\n",
      "‚úÖ Best hyperparameters saved to best_hyperparams.json\n",
      "\n",
      "Top 5 trials:\n",
      "  Trial 0: F1 improvement = 0.0000\n",
      "  Trial 1: F1 improvement = 0.0000\n",
      "  Trial 2: F1 improvement = 0.0000\n",
      "  Trial 3: F1 improvement = 0.0000\n",
      "  Trial 4: F1 improvement = 0.0000\n",
      "\n",
      "------------------------------------------------------------\n",
      "To use these hyperparameters, update utils/config.py:\n",
      "------------------------------------------------------------\n",
      "\n",
      "@dataclass\n",
      "class GANConfig:\n",
      "    # Tuned hyperparameters\n",
      "    latent_dim: int = 100\n",
      "    batch_size: int = 256\n",
      "    lr_g: float = 0.000043\n",
      "    lr_d: float = 0.000412\n",
      "    critic_updates: int = 4\n",
      "    gp_lambda: float = 12.37\n",
      "    feature_matching_weight: float = 0.86\n",
      "    ema_decay: float = 0.9996\n",
      "\n",
      "\n",
      "‚úÖ Tuning completed! Check best_hyperparams.json for optimal values.\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning with Optuna\n",
    "# Skip this cell if you want to use default hyperparameters\n",
    "import subprocess\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"scripts/tune_optuna.py\",\n",
    "    \"--data-root\", str(DATA_ROOT),\n",
    "    \"--dataset\", DATASET,\n",
    "    \"--n-trials\", str(TUNE_TRIALS),\n",
    "    \"--tune-epochs\", str(TUNE_EPOCHS),\n",
    "    \"--max-samples\", str(TUNE_SAMPLES),\n",
    "    \"--seed\", str(SEED),\n",
    "    \"--output\", \"best_hyperparams.json\",\n",
    "]\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"\\n‚è≥ This will run multiple trials to find optimal hyperparameters.\")\n",
    "print(\"üí° Best parameters will be saved to best_hyperparams.json\")\n",
    "\n",
    "result = subprocess.run(cmd, cwd=repo_dir)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n‚úÖ Tuning completed! Check best_hyperparams.json for optimal values.\")\n",
    "elif result.returncode == -9:\n",
    "    print(\"\\n‚ùå Tuning killed (OOM) - Try reducing TUNE_SAMPLES to 50000\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Tuning failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "StealthGAN-IDS Hyperparameter Tuning with Optuna\n",
      "============================================================\n",
      "[tune] Using device: cuda\n",
      "\n",
      "[1/3] Loading data...\n",
      "[tune] Limiting dataset to 400000 samples\n",
      "[CIC-IDS2018] Early stop after 1 files, ~600000 rows\n",
      "[CIC-IDS2018] Sampling 400000 from 600000 rows\n",
      "[CIC-IDS2018] Loaded shape: (400000, 80)\n",
      "[DataForge] Loaded datasets: ['cic_ids2018']\n",
      "[DataForge] Dropped 779 rows with NaN/inf values\n",
      "[DataForge] Data shape after cleaning: (260200, 80)\n",
      "[DataForge] Number of classes: 3\n",
      "[DataForge] Classes: ['Benign', 'FTP-BruteForce', 'SSH-Bruteforce']\n",
      "[DataForge] Split sizes - Train: 182140, Val: 39030, Test: 39030\n",
      "[DataForge] Fitting transformers on training data...\n",
      "[DataForge] Transforming validation data...\n",
      "[DataForge] Transforming test data...\n",
      "[DataForge] Converting sparse to dense...\n",
      "[DataForge] Number of features after encoding: 26528\n",
      "[DataForge] Reducing dimensions from 26528 to 256 using TruncatedSVD...\n",
      "[DataForge] Explained variance: 98.63%\n",
      "[DataForge] Final number of features: 256\n",
      "[tune] Data: 256 features, 3 classes\n",
      "[tune] Train: 182140, Val: 39030\n",
      "[tune] Smaller classes (<27% of equal share): 1 of 3\n",
      "        Class 0:  21784 ( 55.8%)\n",
      "        Class 1:   4834 ( 12.4%) [SMALLER]\n",
      "        Class 2:  12412 ( 31.8%)\n",
      "\n",
      "[tune] Objective = weighted F1 improvement + distribution quality\n",
      "[tune] (adapts based on baseline F1 headroom)\n",
      "\n",
      "[2/3] Creating Optuna study...\n",
      "\u001b[32m[I 2026-01-19 08:27:17,768]\u001b[0m A new study created in memory with name: stealthgan_tuning\u001b[0m\n",
      "\n",
      "[3/3] Running 50 trials (15 epochs each)...\n",
      "============================================================\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\n",
      "[Trial 0] lr_g=4.33e-05, lr_d=4.12e-04, critic=4, gp=12.4, fm=0.86, batch=256\n",
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:841: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:270.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  Epoch 2: D=-238.79 G=585.29 | F1=1.000 (Œî=+0.0000) Q=0.781 cov=0.58 obj=0.5467\n",
      "  Epoch 5: D=-254.11 G=804.86 | F1=1.000 (Œî=+0.0000) Q=0.699 cov=0.33 obj=0.4893\n",
      "  Epoch 8: D=-251.10 G=845.36 | F1=1.000 (Œî=+0.0000) Q=0.668 cov=0.23 obj=0.4677\n",
      "  Epoch 11: D=-252.96 G=846.79 | F1=1.000 (Œî=+0.0000) Q=0.670 cov=0.22 obj=0.4690\n",
      "  Epoch 14: D=-253.13 G=845.64 | F1=1.000 (Œî=+0.0000) Q=0.723 cov=0.34 obj=0.5062\n",
      "\u001b[32m[I 2026-01-19 08:37:58,313]\u001b[0m Trial 0 finished with value: 0.5467427372932434 and parameters: {'lr_g': 4.3284502212938785e-05, 'lr_d': 0.0004123206532618727, 'critic_updates': 4, 'gp_lambda': 12.374511199743695, 'feature_matching_weight': 0.864491338167939, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9996021075364038}. Best is trial 0 with value: 0.5467427372932434.\u001b[0m\n",
      "Best trial: 0. Best value: 0.546743:   2%|    | 1/50 [10:40<8:43:09, 640.60s/it]\n",
      "[Trial 1] lr_g=2.60e-04, lr_d=2.29e-05, critic=1, gp=4.5, fm=1.59, batch=64\n",
      "  Epoch 2: D=-54.34 G=131.08 | F1=1.000 (Œî=+0.0000) Q=0.791 cov=0.65 obj=0.5540\n",
      "  Epoch 5: D=-61.39 G=193.33 | F1=1.000 (Œî=+0.0000) Q=0.856 cov=0.77 obj=0.5994\n",
      "  Epoch 8: D=-62.00 G=198.92 | F1=1.000 (Œî=+0.0000) Q=0.843 cov=0.74 obj=0.5899\n",
      "  Epoch 11: D=-62.21 G=201.14 | F1=1.000 (Œî=+0.0000) Q=0.874 cov=0.81 obj=0.6115\n",
      "  Epoch 14: D=-61.41 G=201.75 | F1=1.000 (Œî=+0.0000) Q=0.872 cov=0.84 obj=0.6107\n",
      "\u001b[32m[I 2026-01-19 08:47:18,925]\u001b[0m Trial 1 finished with value: 0.6115048505485463 and parameters: {'lr_g': 0.00025959425503112657, 'lr_d': 2.2948683681130543e-05, 'critic_updates': 1, 'gp_lambda': 4.484685687215243, 'feature_matching_weight': 1.590786990501735, 'batch_size': 64, 'latent_dim': 64, 'ema_decay': 0.9936269822486076}. Best is trial 1 with value: 0.6115048505485463.\u001b[0m\n",
      "Best trial: 1. Best value: 0.611505:   4%|‚ñè   | 2/50 [20:01<7:54:50, 593.55s/it]\n",
      "[Trial 2] lr_g=5.95e-05, lr_d=2.16e-04, critic=1, gp=10.8, fm=3.00, batch=128\n",
      "  Epoch 2: D=-156.17 G=19.69 | F1=1.000 (Œî=+0.0000) Q=0.695 cov=0.30 obj=0.4862\n",
      "  Epoch 5: D=-175.90 G=26.20 | F1=1.000 (Œî=+0.0000) Q=0.718 cov=0.37 obj=0.5025\n",
      "  Epoch 8: D=-183.45 G=24.09 | F1=1.000 (Œî=+0.0000) Q=0.640 cov=0.16 obj=0.4482\n",
      "  Epoch 11: D=-203.77 G=37.19 | F1=1.000 (Œî=+0.0000) Q=0.710 cov=0.34 obj=0.4967\n",
      "  Epoch 14: D=-154.68 G=15.63 | F1=1.000 (Œî=+0.0000) Q=0.727 cov=0.39 obj=0.5089\n",
      "\u001b[32m[I 2026-01-19 08:52:04,377]\u001b[0m Trial 2 finished with value: 0.5088586785018849 and parameters: {'lr_g': 5.954553793888986e-05, 'lr_d': 0.0002157696745589684, 'critic_updates': 1, 'gp_lambda': 10.770454329858621, 'feature_matching_weight': 3.0028313874240085, 'batch_size': 128, 'latent_dim': 128, 'ema_decay': 0.998003133746353}. Best is trial 1 with value: 0.6115048505485463.\u001b[0m\n",
      "Best trial: 1. Best value: 0.611505:   6%|‚ñè   | 3/50 [24:46<5:54:44, 452.87s/it]\n",
      "[Trial 3] lr_g=3.29e-05, lr_d=1.47e-05, critic=4, gp=9.4, fm=0.70, batch=256\n",
      "  Epoch 2: D=0.42 G=0.81 | F1=1.000 (Œî=+0.0000) Q=0.874 cov=0.80 obj=0.6120\n",
      "  Epoch 5: D=-63.78 G=129.48 | F1=1.000 (Œî=+0.0000) Q=0.847 cov=0.70 obj=0.5932\n",
      "  Epoch 8: D=-278.46 G=961.59 | F1=1.000 (Œî=+0.0000) Q=0.863 cov=0.73 obj=0.6043\n",
      "  Epoch 11: D=-284.00 G=976.84 | F1=1.000 (Œî=+0.0000) Q=0.868 cov=0.74 obj=0.6073\n",
      "  Epoch 14: D=-283.81 G=976.92 | F1=1.000 (Œî=+0.0000) Q=0.870 cov=0.73 obj=0.6094\n",
      "\u001b[32m[I 2026-01-19 09:02:30,728]\u001b[0m Trial 3 finished with value: 0.6120180465400624 and parameters: {'lr_g': 3.292529363110524e-05, 'lr_d': 1.4653521030672129e-05, 'critic_updates': 4, 'gp_lambda': 9.362897381052425, 'feature_matching_weight': 0.6979873507394163, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9951486734096603}. Best is trial 3 with value: 0.6120180465400624.\u001b[0m\n",
      "Best trial: 3. Best value: 0.612018:   8%|‚ñé   | 4/50 [35:13<6:39:42, 521.36s/it]\n",
      "[Trial 4] lr_g=8.49e-05, lr_d=2.06e-05, critic=5, gp=15.7, fm=4.70, batch=256\n",
      "  Epoch 2: D=-205.85 G=596.08 | F1=1.000 (Œî=+0.0000) Q=0.856 cov=0.73 obj=0.5991\n",
      "  Epoch 5: D=-265.71 G=881.34 | F1=1.000 (Œî=+0.0000) Q=0.873 cov=0.75 obj=0.6110\n",
      "  Epoch 8: D=-263.21 G=881.89 | F1=1.000 (Œî=+0.0000) Q=0.889 cov=0.77 obj=0.6225\n",
      "  Epoch 11: D=-264.96 G=881.81 | F1=1.000 (Œî=+0.0000) Q=0.876 cov=0.74 obj=0.6133\n",
      "  Epoch 14: D=-261.76 G=888.16 | F1=1.000 (Œî=+0.0000) Q=0.865 cov=0.71 obj=0.6057\n",
      "\u001b[32m[I 2026-01-19 09:14:00,024]\u001b[0m Trial 4 finished with value: 0.6225320078552175 and parameters: {'lr_g': 8.488762161408708e-05, 'lr_d': 2.060924941320234e-05, 'critic_updates': 5, 'gp_lambda': 15.727523643861176, 'feature_matching_weight': 4.703544813664527, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9932207702745564}. Best is trial 4 with value: 0.6225320078552175.\u001b[0m\n",
      "Best trial: 4. Best value: 0.622532:  10%|‚ñç   | 5/50 [46:42<7:16:26, 581.92s/it]\n",
      "[Trial 5] lr_g=4.57e-05, lr_d=2.89e-05, critic=5, gp=7.8, fm=1.48, batch=256\n",
      "  Epoch 2: D=-263.17 G=457.01 | F1=1.000 (Œî=+0.0000) Q=0.720 cov=0.37 obj=0.5040\n",
      "  Epoch 5: D=-300.63 G=460.72 | F1=1.000 (Œî=+0.0000) Q=0.674 cov=0.25 obj=0.4717\n",
      "\u001b[32m[I 2026-01-19 09:18:37,043]\u001b[0m Trial 5 pruned. \u001b[0m                       \n",
      "Best trial: 4. Best value: 0.622532:  12%|‚ñç   | 6/50 [51:19<5:50:43, 478.25s/it]\n",
      "[Trial 6] lr_g=1.02e-05, lr_d=2.43e-04, critic=4, gp=14.9, fm=3.88, batch=128\n",
      "  Epoch 2: D=-261.72 G=148.83 | F1=1.000 (Œî=+0.0000) Q=0.588 cov=0.13 obj=0.4114\n",
      "  Epoch 5: D=-225.06 G=100.47 | F1=1.000 (Œî=+0.0000) Q=0.471 cov=0.10 obj=0.3298\n",
      "\u001b[32m[I 2026-01-19 09:23:50,169]\u001b[0m Trial 6 pruned. \u001b[0m                       \n",
      "Best trial: 4. Best value: 0.622532:  14%|‚ñå   | 7/50 [56:32<5:04:03, 424.27s/it]\n",
      "[Trial 7] lr_g=3.38e-05, lr_d=3.57e-05, critic=4, gp=13.1, fm=4.45, batch=256\n",
      "  Epoch 2: D=-5.89 G=4.87 | F1=1.000 (Œî=+0.0000) Q=0.797 cov=0.56 obj=0.5581\n",
      "  Epoch 5: D=-272.57 G=922.43 | F1=1.000 (Œî=+0.0000) Q=0.845 cov=0.68 obj=0.5916\n",
      "\u001b[32m[I 2026-01-19 09:28:06,188]\u001b[0m Trial 7 pruned. \u001b[0m                       \n",
      "Best trial: 4. Best value: 0.622532:  16%|‚ñé | 8/50 [1:00:48<4:19:29, 370.71s/it]\n",
      "[Trial 8] lr_g=7.73e-05, lr_d=5.33e-05, critic=1, gp=3.0, fm=0.25, batch=64\n",
      "  Epoch 2: D=-63.32 G=207.00 | F1=1.000 (Œî=+0.0000) Q=0.844 cov=0.71 obj=0.5908\n",
      "  Epoch 5: D=-63.04 G=210.46 | F1=1.000 (Œî=+0.0000) Q=0.864 cov=0.71 obj=0.6045\n",
      "  Epoch 8: D=-63.82 G=209.24 | F1=1.000 (Œî=+0.0000) Q=0.851 cov=0.68 obj=0.5955\n",
      "  Epoch 11: D=-64.11 G=209.71 | F1=1.000 (Œî=+0.0000) Q=0.839 cov=0.64 obj=0.5876\n",
      "\u001b[32m[I 2026-01-19 09:35:31,956]\u001b[0m Trial 8 pruned. \u001b[0m                       \n",
      "Best trial: 4. Best value: 0.622532:  18%|‚ñé | 9/50 [1:08:14<4:29:21, 394.17s/it]\n",
      "[Trial 9] lr_g=2.45e-05, lr_d=1.35e-05, critic=2, gp=4.1, fm=4.66, batch=256\n",
      "  Epoch 2: D=22.25 G=-0.40 | F1=1.000 (Œî=+0.0000) Q=0.797 cov=0.79 obj=0.5577\n",
      "  Epoch 5: D=-19.21 G=8.78 | F1=1.000 (Œî=+0.0000) Q=0.820 cov=0.74 obj=0.5740\n",
      "\u001b[32m[I 2026-01-19 09:38:40,839]\u001b[0m Trial 9 pruned. \u001b[0m                       \n",
      "Best trial: 4. Best value: 0.622532:  20%|‚ñè| 10/50 [1:11:23<3:40:31, 330.79s/it]\n",
      "[Trial 10] lr_g=2.09e-04, lr_d=1.07e-04, critic=5, gp=18.9, fm=3.24, batch=128\n",
      "  Epoch 2: D=-132.33 G=379.25 | F1=1.000 (Œî=+0.0000) Q=0.654 cov=0.17 obj=0.4579\n",
      "  Epoch 5: D=-131.85 G=434.50 | F1=1.000 (Œî=+0.0000) Q=0.783 cov=0.49 obj=0.5481\n",
      "\u001b[32m[I 2026-01-19 09:45:04,821]\u001b[0m Trial 10 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  22%|‚ñè| 11/50 [1:17:47<3:45:35, 347.07s/it]\n",
      "[Trial 11] lr_g=1.25e-04, lr_d=1.03e-05, critic=3, gp=17.5, fm=2.25, batch=256\n",
      "  Epoch 2: D=645.82 G=-9.93 | F1=1.000 (Œî=+0.0000) Q=0.717 cov=0.74 obj=0.5016\n",
      "  Epoch 5: D=1.19 G=-1.59 | F1=1.000 (Œî=+0.0000) Q=0.796 cov=0.83 obj=0.5575\n",
      "\u001b[32m[I 2026-01-19 09:48:57,500]\u001b[0m Trial 11 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  24%|‚ñè| 12/50 [1:21:39<3:17:46, 312.27s/it]\n",
      "[Trial 12] lr_g=1.60e-05, lr_d=1.84e-05, critic=5, gp=8.4, fm=2.24, batch=256\n",
      "  Epoch 2: D=-212.88 G=82.19 | F1=1.000 (Œî=+0.0000) Q=0.758 cov=0.45 obj=0.5309\n",
      "  Epoch 5: D=-262.21 G=34.76 | F1=1.000 (Œî=+0.0000) Q=0.647 cov=0.17 obj=0.4528\n",
      "\u001b[32m[I 2026-01-19 09:53:33,412]\u001b[0m Trial 12 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  26%|‚ñé| 13/50 [1:26:15<3:05:46, 301.26s/it]\n",
      "[Trial 13] lr_g=1.17e-04, lr_d=6.72e-05, critic=3, gp=7.6, fm=4.92, batch=256\n",
      "  Epoch 2: D=-365.01 G=184.14 | F1=1.000 (Œî=+0.0000) Q=0.764 cov=0.50 obj=0.5350\n",
      "  Epoch 5: D=-277.81 G=45.74 | F1=1.000 (Œî=+0.0000) Q=0.767 cov=0.49 obj=0.5368\n",
      "\u001b[32m[I 2026-01-19 09:57:23,218]\u001b[0m Trial 13 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  28%|‚ñé| 14/50 [1:30:05<2:47:48, 279.68s/it]\n",
      "[Trial 14] lr_g=9.79e-05, lr_d=3.98e-05, critic=4, gp=15.8, fm=0.16, batch=256\n",
      "  Epoch 2: D=-206.20 G=606.55 | F1=1.000 (Œî=+0.0000) Q=0.845 cov=0.68 obj=0.5917\n",
      "  Epoch 5: D=-277.28 G=930.08 | F1=1.000 (Œî=+0.0000) Q=0.878 cov=0.75 obj=0.6149\n",
      "  Epoch 8: D=-273.19 G=936.49 | F1=1.000 (Œî=+0.0000) Q=0.879 cov=0.75 obj=0.6155\n",
      "  Epoch 11: D=-274.50 G=934.28 | F1=1.000 (Œî=+0.0000) Q=0.877 cov=0.74 obj=0.6137\n",
      "  Epoch 14: D=-274.16 G=932.44 | F1=1.000 (Œî=+0.0000) Q=0.881 cov=0.74 obj=0.6170\n",
      "\u001b[32m[I 2026-01-19 10:07:57,725]\u001b[0m Trial 14 finished with value: 0.61704611555938 and parameters: {'lr_g': 9.79231646234971e-05, 'lr_d': 3.981233409719855e-05, 'critic_updates': 4, 'gp_lambda': 15.847084597024452, 'feature_matching_weight': 0.16438754701726177, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.99139672885505}. Best is trial 4 with value: 0.6225320078552175.\u001b[0m\n",
      "Best trial: 4. Best value: 0.622532:  30%|‚ñé| 15/50 [1:40:40<3:45:32, 386.63s/it]\n",
      "[Trial 15] lr_g=4.92e-04, lr_d=3.89e-05, critic=3, gp=16.0, fm=3.73, batch=64\n",
      "  Epoch 2: D=-110.95 G=31.27 | F1=1.000 (Œî=+0.0000) Q=0.782 cov=0.81 obj=0.5477\n",
      "  Epoch 5: D=-73.95 G=40.02 | F1=1.000 (Œî=+0.0000) Q=0.681 cov=0.36 obj=0.4765\n",
      "\u001b[32m[I 2026-01-19 10:16:00,476]\u001b[0m Trial 15 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  32%|‚ñé| 16/50 [1:48:42<3:55:29, 415.56s/it]\n",
      "[Trial 16] lr_g=1.01e-04, lr_d=1.22e-04, critic=5, gp=19.6, fm=1.60, batch=256\n",
      "  Epoch 2: D=-266.81 G=843.04 | F1=1.000 (Œî=+0.0000) Q=0.680 cov=0.24 obj=0.4763\n",
      "  Epoch 5: D=-265.81 G=854.18 | F1=1.000 (Œî=+0.0000) Q=0.541 cov=0.13 obj=0.3786\n",
      "\u001b[32m[I 2026-01-19 10:20:39,154]\u001b[0m Trial 16 pruned. \u001b[0m                      \n",
      "Best trial: 4. Best value: 0.622532:  34%|‚ñé| 17/50 [1:53:21<3:25:55, 374.40s/it]\n",
      "[Trial 17] lr_g=1.89e-04, lr_d=4.85e-05, critic=4, gp=15.3, fm=0.10, batch=256\n",
      "  Epoch 2: D=-275.92 G=949.71 | F1=1.000 (Œî=+0.0000) Q=0.885 cov=0.78 obj=0.6192\n",
      "  Epoch 5: D=-282.23 G=950.93 | F1=1.000 (Œî=+0.0000) Q=0.892 cov=0.78 obj=0.6241\n",
      "  Epoch 8: D=-278.25 G=958.04 | F1=1.000 (Œî=+0.0000) Q=0.902 cov=0.80 obj=0.6314\n",
      "  Epoch 11: D=-279.98 G=953.31 | F1=1.000 (Œî=+0.0000) Q=0.892 cov=0.79 obj=0.6241\n",
      "  Epoch 14: D=-279.23 G=956.58 | F1=1.000 (Œî=+0.0000) Q=0.885 cov=0.76 obj=0.6197\n",
      "\u001b[32m[I 2026-01-19 10:31:15,653]\u001b[0m Trial 17 finished with value: 0.6313819885253906 and parameters: {'lr_g': 0.00018928435926843118, 'lr_d': 4.8466658713234654e-05, 'critic_updates': 4, 'gp_lambda': 15.268947484237993, 'feature_matching_weight': 0.10431496421999736, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9921115050227481}. Best is trial 17 with value: 0.6313819885253906.\u001b[0m\n",
      "Best trial: 17. Best value: 0.631382:  36%|‚ñé| 18/50 [2:03:57<4:01:41, 453.16s/it\n",
      "[Trial 18] lr_g=2.07e-04, lr_d=1.15e-04, critic=2, gp=13.7, fm=4.00, batch=128\n",
      "  Epoch 2: D=-128.06 G=345.58 | F1=1.000 (Œî=+0.0000) Q=0.718 cov=0.39 obj=0.5028\n",
      "  Epoch 5: D=-130.30 G=381.75 | F1=1.000 (Œî=+0.0000) Q=0.764 cov=0.53 obj=0.5350\n",
      "\u001b[32m[I 2026-01-19 10:34:15,204]\u001b[0m Trial 18 pruned. \u001b[0m                      \n",
      "Best trial: 17. Best value: 0.631382:  38%|‚ñç| 19/50 [2:06:57<3:11:40, 370.98s/it\n",
      "[Trial 19] lr_g=3.95e-04, lr_d=7.03e-05, critic=5, gp=17.5, fm=2.84, batch=64\n",
      "  Epoch 2: D=-73.61 G=15.54 | F1=1.000 (Œî=+0.0000) Q=0.756 cov=0.48 obj=0.5292\n",
      "  Epoch 5: D=-62.55 G=206.54 | F1=1.000 (Œî=+0.0000) Q=0.822 cov=0.60 obj=0.5757\n",
      "\u001b[32m[I 2026-01-19 10:46:53,240]\u001b[0m Trial 19 pruned. \u001b[0m                      \n",
      "Best trial: 17. Best value: 0.631382:  40%|‚ñç| 20/50 [2:19:35<4:03:35, 487.19s/it\n",
      "[Trial 20] lr_g=1.56e-04, lr_d=1.90e-05, critic=4, gp=11.3, fm=3.41, batch=256\n",
      "  Epoch 2: D=-1.42 G=1.32 | F1=1.000 (Œî=+0.0000) Q=0.841 cov=0.80 obj=0.5884\n",
      "  Epoch 5: D=-211.99 G=481.44 | F1=1.000 (Œî=+0.0000) Q=0.699 cov=0.40 obj=0.4895\n",
      "\u001b[32m[I 2026-01-19 10:51:06,059]\u001b[0m Trial 20 pruned. \u001b[0m                      \n",
      "Best trial: 17. Best value: 0.631382:  42%|‚ñç| 21/50 [2:23:48<3:21:28, 416.84s/it\n",
      "[Trial 21] lr_g=7.73e-05, lr_d=4.35e-05, critic=4, gp=16.3, fm=0.17, batch=256\n",
      "  Epoch 2: D=-252.63 G=823.61 | F1=1.000 (Œî=+0.0000) Q=0.862 cov=0.73 obj=0.6035\n",
      "  Epoch 5: D=-262.10 G=855.92 | F1=1.000 (Œî=+0.0000) Q=0.867 cov=0.73 obj=0.6070\n",
      "  Epoch 8: D=-258.22 G=863.66 | F1=1.000 (Œî=+0.0000) Q=0.858 cov=0.69 obj=0.6004\n",
      "  Epoch 11: D=-259.46 G=861.20 | F1=1.000 (Œî=+0.0000) Q=0.848 cov=0.66 obj=0.5937\n",
      "\u001b[32m[I 2026-01-19 10:59:35,022]\u001b[0m Trial 21 pruned. \u001b[0m                      \n",
      "Best trial: 17. Best value: 0.631382:  44%|‚ñç| 22/50 [2:32:17<3:27:25, 444.49s/it\n",
      "[Trial 22] lr_g=2.96e-04, lr_d=2.96e-05, critic=4, gp=14.5, fm=0.90, batch=256\n",
      "  Epoch 2: D=-251.47 G=823.47 | F1=1.000 (Œî=+0.0000) Q=0.865 cov=0.77 obj=0.6054\n",
      "  Epoch 5: D=-267.28 G=879.85 | F1=1.000 (Œî=+0.0000) Q=0.904 cov=0.83 obj=0.6329\n",
      "  Epoch 8: D=-263.41 G=887.52 | F1=1.000 (Œî=+0.0000) Q=0.900 cov=0.81 obj=0.6303\n",
      "  Epoch 11: D=-264.59 G=884.43 | F1=1.000 (Œî=+0.0000) Q=0.902 cov=0.81 obj=0.6311\n",
      "  Epoch 14: D=-264.31 G=884.77 | F1=1.000 (Œî=+0.0000) Q=0.899 cov=0.80 obj=0.6296\n",
      "\u001b[32m[I 2026-01-19 11:10:03,621]\u001b[0m Trial 22 finished with value: 0.6328538656234741 and parameters: {'lr_g': 0.0002961044208207236, 'lr_d': 2.964039441594639e-05, 'critic_updates': 4, 'gp_lambda': 14.486414221178634, 'feature_matching_weight': 0.9003711002629677, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9923613293866258}. Best is trial 22 with value: 0.6328538656234741.\u001b[0m\n",
      "Best trial: 22. Best value: 0.632854:  46%|‚ñç| 23/50 [2:42:45<3:44:52, 499.74s/it\n",
      "[Trial 23] lr_g=3.19e-04, lr_d=2.83e-05, critic=5, gp=14.3, fm=0.92, batch=256\n",
      "  Epoch 2: D=-93.93 G=220.88 | F1=1.000 (Œî=+0.0000) Q=0.788 cov=0.64 obj=0.5515\n",
      "  Epoch 5: D=-280.65 G=954.98 | F1=1.000 (Œî=+0.0000) Q=0.892 cov=0.79 obj=0.6242\n",
      "  Epoch 8: D=-277.94 G=954.18 | F1=1.000 (Œî=+0.0000) Q=0.882 cov=0.76 obj=0.6175\n",
      "  Epoch 11: D=-279.77 G=954.04 | F1=1.000 (Œî=+0.0000) Q=0.884 cov=0.77 obj=0.6189\n",
      "  Epoch 14: D=-276.47 G=957.79 | F1=1.000 (Œî=+0.0000) Q=0.897 cov=0.80 obj=0.6278\n",
      "\u001b[32m[I 2026-01-19 11:21:37,929]\u001b[0m Trial 23 finished with value: 0.6278237700462341 and parameters: {'lr_g': 0.0003192495658520338, 'lr_d': 2.828536399862355e-05, 'critic_updates': 5, 'gp_lambda': 14.290137501208873, 'feature_matching_weight': 0.9228106755410275, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9921765707150858}. Best is trial 22 with value: 0.6328538656234741.\u001b[0m\n",
      "Best trial: 22. Best value: 0.632854:  48%|‚ñç| 24/50 [2:54:20<4:01:51, 558.12s/it\n",
      "[Trial 24] lr_g=3.05e-04, lr_d=2.75e-05, critic=3, gp=14.1, fm=1.00, batch=256\n",
      "  Epoch 2: D=-0.16 G=0.88 | F1=1.000 (Œî=+0.0000) Q=0.844 cov=0.74 obj=0.5909\n",
      "  Epoch 5: D=-211.79 G=591.94 | F1=1.000 (Œî=+0.0000) Q=0.779 cov=0.60 obj=0.5452\n",
      "\u001b[32m[I 2026-01-19 11:25:30,355]\u001b[0m Trial 24 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  50%|‚ñå| 25/50 [2:58:12<3:11:49, 460.40s/it\n",
      "[Trial 25] lr_g=3.43e-04, lr_d=5.45e-05, critic=4, gp=12.4, fm=1.13, batch=256\n",
      "  Epoch 2: D=-258.06 G=859.17 | F1=1.000 (Œî=+0.0000) Q=0.863 cov=0.76 obj=0.6044\n",
      "  Epoch 5: D=-262.90 G=850.10 | F1=1.000 (Œî=+0.0000) Q=0.854 cov=0.71 obj=0.5981\n",
      "\u001b[32m[I 2026-01-19 11:29:45,605]\u001b[0m Trial 25 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  52%|‚ñå| 26/50 [3:02:27<2:39:32, 398.85s/it\n",
      "[Trial 26] lr_g=1.76e-04, lr_d=8.97e-05, critic=5, gp=14.6, fm=0.65, batch=256\n",
      "  Epoch 2: D=-256.01 G=799.23 | F1=1.000 (Œî=+0.0000) Q=0.657 cov=0.19 obj=0.4596\n",
      "  Epoch 5: D=-257.98 G=796.40 | F1=1.000 (Œî=+0.0000) Q=0.588 cov=0.11 obj=0.4115\n",
      "\u001b[32m[I 2026-01-19 11:34:21,877]\u001b[0m Trial 26 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  54%|‚ñå| 27/50 [3:07:04<2:18:47, 362.07s/it\n",
      "[Trial 27] lr_g=4.62e-04, lr_d=2.96e-05, critic=2, gp=17.7, fm=1.31, batch=128\n",
      "  Epoch 2: D=-122.00 G=341.39 | F1=1.000 (Œî=+0.0000) Q=0.772 cov=0.56 obj=0.5404\n",
      "  Epoch 5: D=-127.51 G=401.05 | F1=1.000 (Œî=+0.0000) Q=0.817 cov=0.70 obj=0.5716\n",
      "\u001b[32m[I 2026-01-19 11:37:21,964]\u001b[0m Trial 27 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  56%|‚ñå| 28/50 [3:10:04<1:52:44, 307.47s/it\n",
      "[Trial 28] lr_g=2.69e-04, lr_d=5.42e-05, critic=3, gp=11.4, fm=1.98, batch=64\n",
      "  Epoch 2: D=-76.25 G=57.87 | F1=1.000 (Œî=+0.0000) Q=0.757 cov=0.51 obj=0.5302\n",
      "  Epoch 5: D=-86.38 G=8.77 | F1=1.000 (Œî=+0.0000) Q=0.738 cov=0.55 obj=0.5168\n",
      "\u001b[32m[I 2026-01-19 11:45:27,060]\u001b[0m Trial 28 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  58%|‚ñå| 29/50 [3:18:09<2:06:16, 360.76s/it\n",
      "[Trial 29] lr_g=1.50e-04, lr_d=4.52e-04, critic=4, gp=12.5, fm=0.57, batch=256\n",
      "  Epoch 2: D=-261.85 G=876.56 | F1=1.000 (Œî=+0.0000) Q=0.683 cov=0.33 obj=0.4781\n",
      "  Epoch 5: D=-264.06 G=875.31 | F1=1.000 (Œî=+0.0000) Q=0.689 cov=0.29 obj=0.4820\n",
      "\u001b[32m[I 2026-01-19 11:49:44,509]\u001b[0m Trial 29 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  60%|‚ñå| 30/50 [3:22:26<1:49:55, 329.77s/it\n",
      "[Trial 30] lr_g=2.50e-04, lr_d=1.43e-05, critic=4, gp=1.3, fm=0.49, batch=256\n",
      "  Epoch 2: D=-110.14 G=121.04 | F1=1.000 (Œî=+0.0000) Q=0.738 cov=0.64 obj=0.5169\n",
      "  Epoch 5: D=-260.03 G=768.50 | F1=1.000 (Œî=+0.0000) Q=0.709 cov=0.43 obj=0.4963\n",
      "\u001b[32m[I 2026-01-19 11:54:00,514]\u001b[0m Trial 30 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  62%|‚ñå| 31/50 [3:26:42<1:37:25, 307.64s/it\n",
      "[Trial 31] lr_g=3.65e-04, lr_d=2.42e-05, critic=5, gp=15.3, fm=0.94, batch=256\n",
      "  Epoch 2: D=-26.28 G=9.56 | F1=1.000 (Œî=+0.0000) Q=0.829 cov=0.76 obj=0.5804\n",
      "  Epoch 5: D=-247.56 G=644.74 | F1=1.000 (Œî=+0.0000) Q=0.844 cov=0.82 obj=0.5909\n",
      "\u001b[32m[I 2026-01-19 11:58:33,223]\u001b[0m Trial 31 pruned. \u001b[0m                      \n",
      "Best trial: 22. Best value: 0.632854:  64%|‚ñã| 32/50 [3:31:15<1:29:08, 297.16s/it\n",
      "[Trial 32] lr_g=1.94e-04, lr_d=2.24e-05, critic=5, gp=18.2, fm=1.81, batch=256\n",
      "  Epoch 2: D=-7.85 G=7.44 | F1=1.000 (Œî=+0.0000) Q=0.854 cov=0.75 obj=0.5976\n",
      "  Epoch 5: D=-293.69 G=1017.30 | F1=1.000 (Œî=+0.0000) Q=0.891 cov=0.84 obj=0.6239\n",
      "  Epoch 8: D=-291.69 G=1019.57 | F1=1.000 (Œî=+0.0000) Q=0.885 cov=0.77 obj=0.6196\n",
      "  Epoch 11: D=-293.70 G=1019.20 | F1=1.000 (Œî=+0.0000) Q=0.903 cov=0.82 obj=0.6319\n",
      "  Epoch 14: D=-290.39 G=1022.59 | F1=1.000 (Œî=+0.0000) Q=0.902 cov=0.81 obj=0.6312\n",
      "\u001b[32m[I 2026-01-19 12:10:05,064]\u001b[0m Trial 32 finished with value: 0.6319495439529419 and parameters: {'lr_g': 0.00019395051392687368, 'lr_d': 2.2442698353320372e-05, 'critic_updates': 5, 'gp_lambda': 18.236410838129796, 'feature_matching_weight': 1.8091021925420292, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.993317758810998}. Best is trial 22 with value: 0.6328538656234741.\u001b[0m\n",
      "Best trial: 22. Best value: 0.632854:  66%|‚ñã| 33/50 [3:42:47<1:57:44, 415.56s/it\n",
      "[Trial 33] lr_g=2.19e-04, lr_d=3.22e-05, critic=5, gp=18.4, fm=1.85, batch=256\n",
      "  Epoch 2: D=-164.64 G=481.33 | F1=1.000 (Œî=+0.0000) Q=0.867 cov=0.78 obj=0.6068\n",
      "  Epoch 5: D=-285.49 G=978.11 | F1=1.000 (Œî=+0.0000) Q=0.897 cov=0.81 obj=0.6282\n",
      "  Epoch 8: D=-282.62 G=976.98 | F1=1.000 (Œî=+0.0000) Q=0.904 cov=0.81 obj=0.6327\n",
      "  Epoch 11: D=-284.47 G=976.40 | F1=1.000 (Œî=+0.0000) Q=0.913 cov=0.84 obj=0.6391\n",
      "  Epoch 14: D=-281.11 G=979.75 | F1=1.000 (Œî=+0.0000) Q=0.900 cov=0.80 obj=0.6300\n",
      "\u001b[32m[I 2026-01-19 12:21:31,813]\u001b[0m Trial 33 finished with value: 0.6390760518730092 and parameters: {'lr_g': 0.00021907262577734783, 'lr_d': 3.215403791065063e-05, 'critic_updates': 5, 'gp_lambda': 18.359979115830047, 'feature_matching_weight': 1.8454027656038325, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9922310316139415}. Best is trial 33 with value: 0.6390760518730092.\u001b[0m\n",
      "Best trial: 33. Best value: 0.639076:  68%|‚ñã| 34/50 [3:54:14<2:12:30, 496.92s/it\n",
      "[Trial 34] lr_g=2.32e-04, lr_d=3.41e-05, critic=5, gp=18.4, fm=1.71, batch=256\n",
      "  Epoch 2: D=-229.48 G=741.87 | F1=1.000 (Œî=+0.0000) Q=0.883 cov=0.82 obj=0.6182\n",
      "  Epoch 5: D=-299.49 G=1042.17 | F1=1.000 (Œî=+0.0000) Q=0.894 cov=0.80 obj=0.6257\n",
      "  Epoch 8: D=-296.43 G=1041.75 | F1=1.000 (Œî=+0.0000) Q=0.893 cov=0.79 obj=0.6250\n",
      "  Epoch 11: D=-298.34 G=1042.22 | F1=1.000 (Œî=+0.0000) Q=0.884 cov=0.76 obj=0.6186\n",
      "  Epoch 14: D=-294.87 G=1044.55 | F1=1.000 (Œî=+0.0000) Q=0.886 cov=0.76 obj=0.6199\n",
      "\u001b[32m[I 2026-01-19 12:33:07,090]\u001b[0m Trial 34 finished with value: 0.6257199622810292 and parameters: {'lr_g': 0.0002324888473238189, 'lr_d': 3.4143349553590095e-05, 'critic_updates': 5, 'gp_lambda': 18.371672475922388, 'feature_matching_weight': 1.714402121563607, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.993556929769821}. Best is trial 33 with value: 0.6390760518730092.\u001b[0m\n",
      "Best trial: 33. Best value: 0.639076:  70%|‚ñã| 35/50 [4:05:49<2:19:06, 556.43s/it\n",
      "[Trial 35] lr_g=1.89e-04, lr_d=2.20e-05, critic=4, gp=20.0, fm=2.57, batch=256\n",
      "  Epoch 2: D=-94.31 G=205.59 | F1=1.000 (Œî=+0.0000) Q=0.833 cov=0.72 obj=0.5833\n",
      "  Epoch 5: D=-276.53 G=925.53 | F1=1.000 (Œî=+0.0000) Q=0.856 cov=0.81 obj=0.5989\n",
      "\u001b[32m[I 2026-01-19 12:37:21,720]\u001b[0m Trial 35 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  72%|‚ñã| 36/50 [4:10:04<1:48:42, 465.89s/it\n",
      "[Trial 36] lr_g=5.86e-05, lr_d=1.75e-05, critic=5, gp=16.9, fm=1.90, batch=256\n",
      "  Epoch 2: D=-34.87 G=45.83 | F1=1.000 (Œî=+0.0000) Q=0.840 cov=0.71 obj=0.5878\n",
      "  Epoch 5: D=-274.99 G=928.63 | F1=1.000 (Œî=+0.0000) Q=0.865 cov=0.75 obj=0.6053\n",
      "\u001b[32m[I 2026-01-19 12:41:57,823]\u001b[0m Trial 36 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  74%|‚ñã| 37/50 [4:14:40<1:28:36, 408.95s/it\n",
      "[Trial 37] lr_g=1.27e-04, lr_d=4.66e-05, critic=5, gp=18.6, fm=1.27, batch=128\n",
      "  Epoch 2: D=-128.00 G=204.10 | F1=1.000 (Œî=+0.0000) Q=0.789 cov=0.53 obj=0.5522\n",
      "  Epoch 5: D=-133.13 G=357.81 | F1=1.000 (Œî=+0.0000) Q=0.734 cov=0.37 obj=0.5136\n",
      "\u001b[32m[I 2026-01-19 12:48:18,551]\u001b[0m Trial 37 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  76%|‚ñä| 38/50 [4:21:00<1:20:05, 400.49s/it\n",
      "[Trial 38] lr_g=1.57e-04, lr_d=3.17e-04, critic=4, gp=16.7, fm=2.29, batch=64\n",
      "  Epoch 2: D=-91.44 G=11.55 | F1=1.000 (Œî=+0.0000) Q=0.807 cov=0.58 obj=0.5649\n",
      "  Epoch 5: D=-73.12 G=157.49 | F1=1.000 (Œî=+0.0000) Q=0.838 cov=0.66 obj=0.5864\n",
      "\u001b[32m[I 2026-01-19 12:58:40,217]\u001b[0m Trial 38 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  78%|‚ñä| 39/50 [4:31:22<1:25:35, 466.84s/it\n",
      "[Trial 39] lr_g=2.84e-04, lr_d=1.17e-05, critic=5, gp=6.4, fm=1.48, batch=256\n",
      "  Epoch 2: D=-3.34 G=-0.79 | F1=1.000 (Œî=+0.0000) Q=0.805 cov=0.83 obj=0.5633\n",
      "  Epoch 5: D=-178.87 G=412.08 | F1=1.000 (Œî=+0.0000) Q=0.693 cov=0.39 obj=0.4853\n",
      "\u001b[32m[I 2026-01-19 13:03:17,611]\u001b[0m Trial 39 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  80%|‚ñä| 40/50 [4:35:59<1:08:20, 410.01s/it\n",
      "[Trial 40] lr_g=4.22e-04, lr_d=2.37e-05, critic=4, gp=9.8, fm=0.44, batch=256\n",
      "  Epoch 2: D=-25.69 G=31.27 | F1=1.000 (Œî=+0.0000) Q=0.750 cov=0.61 obj=0.5249\n",
      "  Epoch 5: D=-307.56 G=641.64 | F1=1.000 (Œî=+0.0000) Q=0.687 cov=0.48 obj=0.4812\n",
      "\u001b[32m[I 2026-01-19 13:07:30,475]\u001b[0m Trial 40 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  82%|‚ñà‚ñã| 41/50 [4:40:12<54:25, 362.86s/it]\n",
      "[Trial 41] lr_g=2.96e-04, lr_d=3.12e-05, critic=5, gp=13.8, fm=0.80, batch=256\n",
      "  Epoch 2: D=-94.63 G=217.38 | F1=1.000 (Œî=+0.0000) Q=0.703 cov=0.38 obj=0.4919\n",
      "  Epoch 5: D=-290.08 G=1000.43 | F1=1.000 (Œî=+0.0000) Q=0.892 cov=0.81 obj=0.6247\n",
      "  Epoch 8: D=-287.33 G=998.44 | F1=1.000 (Œî=+0.0000) Q=0.875 cov=0.75 obj=0.6125\n",
      "  Epoch 11: D=-289.23 G=998.81 | F1=1.000 (Œî=+0.0000) Q=0.870 cov=0.73 obj=0.6087\n",
      "  Epoch 14: D=-285.84 G=1002.34 | F1=1.000 (Œî=+0.0000) Q=0.868 cov=0.73 obj=0.6078\n",
      "\u001b[32m[I 2026-01-19 13:18:59,223]\u001b[0m Trial 41 finished with value: 0.624707636994164 and parameters: {'lr_g': 0.00029600499941210466, 'lr_d': 3.1160887937135135e-05, 'critic_updates': 5, 'gp_lambda': 13.769047700643311, 'feature_matching_weight': 0.8032104778143714, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9921142513624934}. Best is trial 33 with value: 0.6390760518730092.\u001b[0m\n",
      "Best trial: 33. Best value: 0.639076:  84%|‚ñä| 42/50 [4:51:41<1:01:25, 460.63s/it\n",
      "[Trial 42] lr_g=3.38e-04, lr_d=2.73e-05, critic=5, gp=15.4, fm=1.86, batch=256\n",
      "  Epoch 2: D=-60.36 G=120.10 | F1=1.000 (Œî=+0.0000) Q=0.834 cov=0.71 obj=0.5841\n",
      "  Epoch 5: D=-275.51 G=931.23 | F1=1.000 (Œî=+0.0000) Q=0.895 cov=0.82 obj=0.6262\n",
      "  Epoch 8: D=-273.02 G=931.20 | F1=1.000 (Œî=+0.0000) Q=0.909 cov=0.83 obj=0.6361\n",
      "  Epoch 11: D=-274.85 G=930.17 | F1=1.000 (Œî=+0.0000) Q=0.897 cov=0.79 obj=0.6278\n",
      "  Epoch 14: D=-271.62 G=934.60 | F1=1.000 (Œî=+0.0000) Q=0.899 cov=0.80 obj=0.6291\n",
      "\u001b[32m[I 2026-01-19 13:30:32,768]\u001b[0m Trial 42 finished with value: 0.6361292600631714 and parameters: {'lr_g': 0.0003375878391028863, 'lr_d': 2.7324764120605306e-05, 'critic_updates': 5, 'gp_lambda': 15.423501955138626, 'feature_matching_weight': 1.8574141375656503, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9931355491007074}. Best is trial 33 with value: 0.6390760518730092.\u001b[0m\n",
      "Best trial: 33. Best value: 0.639076:  86%|‚ñä| 43/50 [5:03:15<1:01:53, 530.50s/it\n",
      "[Trial 43] lr_g=2.09e-04, lr_d=1.60e-05, critic=5, gp=17.9, fm=1.83, batch=256\n",
      "  Epoch 2: D=0.22 G=1.25 | F1=1.000 (Œî=+0.0000) Q=0.849 cov=0.74 obj=0.5941\n",
      "  Epoch 5: D=-235.63 G=666.94 | F1=1.000 (Œî=+0.0000) Q=0.794 cov=0.65 obj=0.5558\n",
      "\u001b[32m[I 2026-01-19 13:35:06,130]\u001b[0m Trial 43 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  88%|‚ñà‚ñä| 44/50 [5:07:48<45:20, 453.36s/it]\n",
      "[Trial 44] lr_g=2.46e-04, lr_d=2.38e-05, critic=5, gp=16.9, fm=2.55, batch=256\n",
      "  Epoch 2: D=-23.73 G=41.77 | F1=1.000 (Œî=+0.0000) Q=0.866 cov=0.78 obj=0.6063\n",
      "  Epoch 5: D=-289.82 G=998.00 | F1=1.000 (Œî=+0.0000) Q=0.895 cov=0.84 obj=0.6266\n",
      "  Epoch 8: D=-287.19 G=998.81 | F1=1.000 (Œî=+0.0000) Q=0.894 cov=0.80 obj=0.6261\n",
      "  Epoch 11: D=-289.14 G=998.98 | F1=1.000 (Œî=+0.0000) Q=0.887 cov=0.78 obj=0.6208\n",
      "  Epoch 14: D=-285.82 G=1002.55 | F1=1.000 (Œî=+0.0000) Q=0.900 cov=0.80 obj=0.6302\n",
      "\u001b[32m[I 2026-01-19 13:46:36,164]\u001b[0m Trial 44 finished with value: 0.6301540114105153 and parameters: {'lr_g': 0.0002455917449297337, 'lr_d': 2.379246093560719e-05, 'critic_updates': 5, 'gp_lambda': 16.932598519395064, 'feature_matching_weight': 2.5474181957960633, 'batch_size': 256, 'latent_dim': 100, 'ema_decay': 0.9945733454796029}. Best is trial 33 with value: 0.6390760518730092.\u001b[0m\n",
      "Best trial: 33. Best value: 0.639076:  90%|‚ñà‚ñä| 45/50 [5:19:18<43:41, 524.36s/it]\n",
      "[Trial 45] lr_g=5.70e-05, lr_d=3.52e-05, critic=4, gp=15.1, fm=2.04, batch=256\n",
      "  Epoch 2: D=-252.93 G=732.42 | F1=1.000 (Œî=+0.0000) Q=0.752 cov=0.45 obj=0.5263\n",
      "  Epoch 5: D=-257.28 G=822.90 | F1=1.000 (Œî=+0.0000) Q=0.761 cov=0.48 obj=0.5329\n",
      "\u001b[32m[I 2026-01-19 13:50:48,821]\u001b[0m Trial 45 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  92%|‚ñà‚ñä| 46/50 [5:23:31<29:31, 442.85s/it]\n",
      "[Trial 46] lr_g=3.73e-04, lr_d=4.84e-05, critic=5, gp=12.8, fm=1.25, batch=256\n",
      "  Epoch 2: D=-264.92 G=889.49 | F1=1.000 (Œî=+0.0000) Q=0.878 cov=0.75 obj=0.6145\n",
      "  Epoch 5: D=-266.82 G=879.26 | F1=1.000 (Œî=+0.0000) Q=0.888 cov=0.81 obj=0.6213\n",
      "\u001b[32m[I 2026-01-19 13:55:27,520]\u001b[0m Trial 46 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  94%|‚ñà‚ñâ| 47/50 [5:28:09<19:40, 393.61s/it]\n",
      "[Trial 47] lr_g=1.72e-04, lr_d=6.18e-05, critic=4, gp=19.0, fm=2.50, batch=128\n",
      "  Epoch 2: D=-182.20 G=44.92 | F1=1.000 (Œî=+0.0000) Q=0.796 cov=0.72 obj=0.5572\n",
      "  Epoch 5: D=28480155.76 G=292.47 | F1=1.000 (Œî=+0.0000) Q=0.767 cov=0.84 obj=0.5372\n",
      "\u001b[32m[I 2026-01-19 14:00:40,289]\u001b[0m Trial 47 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  96%|‚ñà‚ñâ| 48/50 [5:33:22<12:18, 369.35s/it]\n",
      "[Trial 48] lr_g=1.31e-04, lr_d=2.05e-05, critic=3, gp=15.6, fm=1.46, batch=256\n",
      "  Epoch 2: D=2.15 G=0.21 | F1=1.000 (Œî=+0.0000) Q=0.852 cov=0.85 obj=0.5962\n",
      "  Epoch 5: D=-144.82 G=375.82 | F1=1.000 (Œî=+0.0000) Q=0.862 cov=0.79 obj=0.6033\n",
      "\u001b[32m[I 2026-01-19 14:04:32,221]\u001b[0m Trial 48 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076:  98%|‚ñà‚ñâ| 49/50 [5:37:14<05:28, 328.13s/it]\n",
      "[Trial 49] lr_g=2.09e-04, lr_d=1.78e-04, critic=5, gp=19.1, fm=0.29, batch=64\n",
      "  Epoch 2: D=-109.33 G=52.22 | F1=1.000 (Œî=+0.0000) Q=0.587 cov=0.14 obj=0.4108\n",
      "  Epoch 5: D=3.86 G=19.40 | F1=1.000 (Œî=+0.0000) Q=0.804 cov=0.56 obj=0.5626\n",
      "\u001b[32m[I 2026-01-19 14:17:02,680]\u001b[0m Trial 49 pruned. \u001b[0m                      \n",
      "Best trial: 33. Best value: 0.639076: 100%|‚ñà‚ñà| 50/50 [5:49:44<00:00, 419.70s/it]\n",
      "\n",
      "============================================================\n",
      "TUNING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Study statistics:\n",
      "  Number of finished trials: 50\n",
      "  Number of pruned trials: 35\n",
      "  Number of complete trials: 15\n",
      "\n",
      "Best trial:\n",
      "  Objective value: 0.6391\n",
      "  (combines weighted F1 improvement + distribution quality)\n",
      "  Params:\n",
      "    lr_g: 0.000219\n",
      "    lr_d: 0.000032\n",
      "    critic_updates: 5\n",
      "    gp_lambda: 18.359979\n",
      "    feature_matching_weight: 1.845403\n",
      "    batch_size: 256\n",
      "    latent_dim: 100\n",
      "    ema_decay: 0.992231\n",
      "\n",
      "‚úÖ Best hyperparameters saved to best_hyperparams.json\n",
      "\n",
      "Top 5 trials:\n",
      "  Trial 33: objective = 0.6391\n",
      "  Trial 42: objective = 0.6361\n",
      "  Trial 22: objective = 0.6329\n",
      "  Trial 32: objective = 0.6319\n",
      "  Trial 17: objective = 0.6314\n",
      "\n",
      "------------------------------------------------------------\n",
      "To use these hyperparameters, update utils/config.py:\n",
      "------------------------------------------------------------\n",
      "\n",
      "@dataclass\n",
      "class GANConfig:\n",
      "    # Tuned hyperparameters\n",
      "    latent_dim: int = 100\n",
      "    batch_size: int = 256\n",
      "    lr_g: float = 0.000219\n",
      "    lr_d: float = 0.000032\n",
      "    critic_updates: int = 5\n",
      "    gp_lambda: float = 18.36\n",
      "    feature_matching_weight: float = 1.85\n",
      "    ema_decay: float = 0.9922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python scripts/tune_optuna.py --data-root /workspace/data --dataset cic_ids2018 --n-trials 50 --max-samples 400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tuning results\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "hp_file = repo_dir / \"best_hyperparams.json\"\n",
    "if hp_file.exists():\n",
    "    with open(hp_file) as f:\n",
    "        best_hp = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Best Hyperparameters Found\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nF1 Improvement: {best_hp['best_value']:.4f}\")\n",
    "    print(f\"Total trials: {best_hp['n_trials']}\")\n",
    "    print(\"\\nOptimal parameters:\")\n",
    "    for key, value in best_hp['params'].items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\nüí° These values will be used for full training below.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No tuning results found. Run tuning first or skip to use defaults.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Training\n",
    "\n",
    "Train the GAN with optimal hyperparameters (from tuning or defaults)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128  # Will be overridden by tuned value if available\n",
    "MAX_SAMPLES = 300000  # Limit dataset size for memory\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "USE_AMP = True  # Mixed precision\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Load tuned hyperparameters if available\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "hp_file = repo_dir / \"best_hyperparams.json\"\n",
    "tuned_params = {}\n",
    "if hp_file.exists():\n",
    "    with open(hp_file) as f:\n",
    "        best_hp = json.load(f)\n",
    "    tuned_params = best_hp.get('params', {})\n",
    "    if 'batch_size' in tuned_params:\n",
    "        BATCH_SIZE = tuned_params['batch_size']\n",
    "    print(\"‚úÖ Using tuned hyperparameters\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No tuned parameters found, using defaults\")\n",
    "\n",
    "# Clear GPU memory\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Dataset: {DATASET}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Max samples: {MAX_SAMPLES}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Mixed precision: {USE_AMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start full training\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"scripts/train_gan.py\",\n",
    "    \"--data-root\", str(DATA_ROOT),\n",
    "    \"--dataset\", DATASET,\n",
    "    \"--epochs\", str(EPOCHS),\n",
    "    \"--batch-size\", str(BATCH_SIZE),\n",
    "    \"--checkpoint-interval\", str(CHECKPOINT_INTERVAL),\n",
    "    \"--seed\", str(SEED),\n",
    "    \"--num-workers\", str(NUM_WORKERS),\n",
    "]\n",
    "\n",
    "if MAX_SAMPLES:\n",
    "    cmd.extend([\"--max-samples\", str(MAX_SAMPLES)])\n",
    "\n",
    "if USE_AMP:\n",
    "    cmd.append(\"--amp\")\n",
    "\n",
    "print(\"Starting full training...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"\\n‚ö†Ô∏è  This may take several hours. Checkpoints will be saved periodically.\")\n",
    "print(\"üí° If you get OOM errors, reduce MAX_SAMPLES (try 200000) or BATCH_SIZE (try 64)\")\n",
    "\n",
    "result = subprocess.run(cmd, cwd=repo_dir)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "elif result.returncode == -9:\n",
    "    print(\"\\n‚ùå Training killed (exit code -9) - Out of Memory!\")\n",
    "    print(\"   Try reducing MAX_SAMPLES to 200000 or BATCH_SIZE to 64\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Training failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training outputs\n",
    "output_files = [\n",
    "    \"training_stats.csv\",\n",
    "    \"generator_best.pth\",\n",
    "    \"generator_ema_best.pth\",\n",
    "    \"generator.pth\",\n",
    "    \"discriminator.pth\",\n",
    "]\n",
    "\n",
    "print(\"Training outputs:\")\n",
    "for fname in output_files:\n",
    "    path = repo_dir / fname\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / 1e6\n",
    "        print(f\"  ‚úÖ {fname} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {fname} (not found)\")\n",
    "\n",
    "# List checkpoints\n",
    "checkpoints = list(repo_dir.glob(\"checkpoint_epoch_*.pth\"))\n",
    "if checkpoints:\n",
    "    print(f\"\\nCheckpoints found: {len(checkpoints)}\")\n",
    "    for cp in sorted(checkpoints)[-5:]:  # Show last 5\n",
    "        size_mb = cp.stat().st_size / 1e6\n",
    "        print(f\"  {cp.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate the trained generator with comprehensive metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation configuration\n",
    "GENERATOR_PATH = \"generator_ema_best.pth\"  # Use EMA version (better quality)\n",
    "N_PER_CLASS = 2000  # Synthetic samples per class\n",
    "TARGET_MINORITY = True  # Focus on minority classes\n",
    "CV_FOLDS = 5  # Cross-validation folds\n",
    "OUTPUT_DIR = \"eval_outputs\"\n",
    "\n",
    "print(f\"Evaluation configuration:\")\n",
    "print(f\"  Generator: {GENERATOR_PATH}\")\n",
    "print(f\"  Samples per class: {N_PER_CLASS}\")\n",
    "print(f\"  Target minority: {TARGET_MINORITY}\")\n",
    "print(f\"  CV folds: {CV_FOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "import subprocess\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear memory before evaluation\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"scripts/eval_gan.py\",\n",
    "    \"--data-root\", str(DATA_ROOT),\n",
    "    \"--dataset\", DATASET,\n",
    "    \"--generator-path\", GENERATOR_PATH,\n",
    "    \"--n-per-class\", str(N_PER_CLASS),\n",
    "    \"--cv-folds\", str(CV_FOLDS),\n",
    "    \"--output-dir\", OUTPUT_DIR,\n",
    "]\n",
    "\n",
    "# Pass max_samples to prevent OOM during data loading\n",
    "if MAX_SAMPLES:\n",
    "    cmd.extend([\"--max-samples\", str(MAX_SAMPLES)])\n",
    "\n",
    "if TARGET_MINORITY:\n",
    "    cmd.append(\"--target-minority\")\n",
    "\n",
    "print(\"Starting evaluation...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "result = subprocess.run(cmd, cwd=repo_dir)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n‚úÖ Evaluation completed successfully!\")\n",
    "elif result.returncode == -9:\n",
    "    print(\"\\n‚ùå Evaluation killed (exit code -9) - Out of Memory!\")\n",
    "    print(\"   Try reducing MAX_SAMPLES to 200000 or N_PER_CLASS to 1000\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Evaluation failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View evaluation results\n",
    "import json\n",
    "\n",
    "results_file = repo_dir / OUTPUT_DIR / \"evaluation_results.json\"\n",
    "if results_file.exists():\n",
    "    with open(results_file) as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"Evaluation Results Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if \"classifier_results\" in results:\n",
    "        print(\"\\nClassifier Performance:\")\n",
    "        for classifier, metrics in results[\"classifier_results\"].items():\n",
    "            if \"baseline\" in metrics and \"augmented\" in metrics:\n",
    "                baseline = metrics[\"baseline\"][\"mean\"]\n",
    "                augmented = metrics[\"augmented\"][\"mean\"]\n",
    "                improvement = augmented - baseline\n",
    "                print(f\"  {classifier}:\")\n",
    "                print(f\"    Baseline F1: {baseline:.4f}\")\n",
    "                print(f\"    Augmented F1: {augmented:.4f}\")\n",
    "                print(f\"    Improvement: {improvement:+.4f}\")\n",
    "    \n",
    "    if \"distribution_metrics\" in results:\n",
    "        print(\"\\nDistribution Quality:\")\n",
    "        for metric, value in results[\"distribution_metrics\"].items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Results file not found. Run evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "View generated plots and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plots_dir = repo_dir / OUTPUT_DIR / \"plots\"\n",
    "if plots_dir.exists():\n",
    "    plot_files = list(plots_dir.glob(\"*.png\"))\n",
    "    if plot_files:\n",
    "        print(f\"Found {len(plot_files)} plot(s):\")\n",
    "        for plot_file in plot_files:\n",
    "            print(f\"\\n{plot_file.name}:\")\n",
    "            display(Image(str(plot_file)))\n",
    "    else:\n",
    "        print(\"No plots found in plots directory.\")\n",
    "else:\n",
    "    print(\"Plots directory not found. Run evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Results\n",
    "\n",
    "Download your trained models and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create download package\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "download_dir = Path(\"/content/downloads\")\n",
    "download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy important files\n",
    "files_to_download = [\n",
    "    \"generator_ema_best.pth\",\n",
    "    \"generator_best.pth\",\n",
    "    \"discriminator.pth\",\n",
    "    \"training_stats.csv\",\n",
    "]\n",
    "\n",
    "# Copy checkpoints\n",
    "checkpoints = list(repo_dir.glob(\"checkpoint_epoch_*.pth\"))\n",
    "if checkpoints:\n",
    "    checkpoint_dir = download_dir / \"checkpoints\"\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    for cp in checkpoints:\n",
    "        shutil.copy2(cp, checkpoint_dir / cp.name)\n",
    "    print(f\"Copied {len(checkpoints)} checkpoints\")\n",
    "\n",
    "# Copy evaluation outputs\n",
    "eval_dir = repo_dir / OUTPUT_DIR\n",
    "if eval_dir.exists():\n",
    "    shutil.copytree(eval_dir, download_dir / OUTPUT_DIR, dirs_exist_ok=True)\n",
    "    print(\"Copied evaluation outputs\")\n",
    "\n",
    "# Copy files\n",
    "for fname in files_to_download:\n",
    "    src = repo_dir / fname\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, download_dir / fname)\n",
    "\n",
    "print(f\"\\n‚úÖ Files prepared for download in {download_dir}\")\n",
    "print(\"\\nTo download:\")\n",
    "print(\"1. Use Colab file browser (left sidebar)\")\n",
    "print(\"2. Navigate to /content/downloads\")\n",
    "print(\"3. Right-click files and select 'Download'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Create a zip file for easy download\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "zip_path = \"/content/stealthgan_results.zip\"\n",
    "download_dir = Path(\"/content/downloads\")\n",
    "\n",
    "if download_dir.exists():\n",
    "    shutil.make_archive(\n",
    "        zip_path.replace(\".zip\", \"\"),\n",
    "        \"zip\",\n",
    "        download_dir\n",
    "    )\n",
    "    \n",
    "    size_mb = Path(zip_path).stat().st_size / 1e6\n",
    "    print(f\"‚úÖ Created zip file: {zip_path} ({size_mb:.2f} MB)\")\n",
    "    print(\"\\nDownloading zip file...\")\n",
    "    files.download(zip_path)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Download directory not found. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume Training (Optional)\n",
    "\n",
    "Resume training from a checkpoint if your session disconnects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training from checkpoint\n",
    "CHECKPOINT_PATH = \"checkpoint_epoch_50.pth\"  # ‚ö†Ô∏è Update with your checkpoint name\n",
    "RESUME_EPOCHS = 100  # Total epochs (will continue from checkpoint)\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"scripts/train_gan.py\",\n",
    "    \"--data-root\", str(DATA_ROOT),\n",
    "    \"--dataset\", DATASET,\n",
    "    \"--epochs\", str(RESUME_EPOCHS),\n",
    "    \"--batch-size\", str(BATCH_SIZE),\n",
    "    \"--resume\", CHECKPOINT_PATH,\n",
    "    \"--seed\", str(SEED),\n",
    "    \"--num-workers\", str(NUM_WORKERS),\n",
    "]\n",
    "\n",
    "if MAX_SAMPLES:\n",
    "    cmd.extend([\"--max-samples\", str(MAX_SAMPLES)])\n",
    "\n",
    "if USE_AMP:\n",
    "    cmd.append(\"--amp\")\n",
    "\n",
    "print(\"To resume training, update CHECKPOINT_PATH above and uncomment the last line:\")\n",
    "print(f\"{' '.join(cmd)}\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# result = subprocess.run(cmd, cwd=repo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "**Common Issues:**\n",
    "\n",
    "1. **Out of Memory (exit code -9)**:\n",
    "   - Reduce `MAX_SAMPLES` (try 200000 or 100000)\n",
    "   - Reduce `BATCH_SIZE` (try 32 or 16)\n",
    "   - Use a smaller dataset (`nsl_kdd` instead of `cic_ids2018`)\n",
    "2. **Session Timeout**: Colab free tier has 12hr limit. Use checkpoints to resume.\n",
    "3. **Dataset Not Found**: Ensure dataset is downloaded and extracted correctly.\n",
    "4. **Slow Training**: Enable GPU (Runtime > Change runtime type > GPU)\n",
    "\n",
    "**Memory Guide for Colab Free Tier (12GB RAM):**\n",
    "| Dataset | Recommended MAX_SAMPLES |\n",
    "|---------|------------------------|\n",
    "| NSL-KDD | None (all ~125K) |\n",
    "| CIC-IDS2017 | 500000 |\n",
    "| CIC-IDS2018 | 500000 |\n",
    "| UNSW-NB15 | None (all ~175K) |\n",
    "\n",
    "**Tips:**\n",
    "- Save checkpoints frequently\n",
    "- Use Colab Pro for longer sessions (24hr limit) and more RAM\n",
    "- Download results before session expires\n",
    "- Monitor GPU usage: `!nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
